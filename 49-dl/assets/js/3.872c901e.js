(window.webpackJsonp=window.webpackJsonp||[]).push([[3],{359:function(e,t,a){e.exports=a.p+"assets/img/figure136.e5a54161.png"},447:function(e,t,a){e.exports=a.p+"assets/img/figure160.4c069b05.png"},448:function(e,t,a){e.exports=a.p+"assets/img/figure25.02c5881d.png"},449:function(e,t,a){e.exports=a.p+"assets/img/figure26.8687950c.png"},450:function(e,t,a){e.exports=a.p+"assets/img/figure27.f45ff5d6.png"},451:function(e,t,a){e.exports=a.p+"assets/img/figure28.0673e4a6.png"},452:function(e,t,a){e.exports=a.p+"assets/img/figure29.4a137a14.png"},453:function(e,t,a){e.exports=a.p+"assets/img/figure30.5f3c9359.png"},454:function(e,t,a){e.exports=a.p+"assets/img/figure31.97c463de.png"},455:function(e,t,a){e.exports=a.p+"assets/img/figure32.ee9dc550.png"},456:function(e,t,a){e.exports=a.p+"assets/img/figure33.ac5c9eb6.png"},457:function(e,t,a){e.exports=a.p+"assets/img/figure34.9144ba44.png"},458:function(e,t,a){e.exports=a.p+"assets/img/figure35.2f2db35e.png"},459:function(e,t,a){e.exports=a.p+"assets/img/figure36.4a641c3e.png"},460:function(e,t,a){e.exports=a.p+"assets/img/figure37.da6b554d.png"},461:function(e,t,a){e.exports=a.p+"assets/img/figure38.de819541.png"},462:function(e,t,a){e.exports=a.p+"assets/img/figure39.1c565354.png"},463:function(e,t,a){e.exports=a.p+"assets/img/figure40.493690e9.png"},464:function(e,t,a){e.exports=a.p+"assets/img/figure41.de09f86d.png"},465:function(e,t,a){e.exports=a.p+"assets/img/figure42.93759b94.png"},466:function(e,t,a){e.exports=a.p+"assets/img/figure43.ead1f83f.png"},467:function(e,t,a){e.exports=a.p+"assets/img/figure44.9ea7487b.png"},468:function(e,t,a){e.exports=a.p+"assets/img/figure45.f9648fc8.png"},469:function(e,t,a){e.exports=a.p+"assets/img/figure46.58c48213.png"},470:function(e,t,a){e.exports=a.p+"assets/img/figure47.93759b94.png"},471:function(e,t,a){e.exports=a.p+"assets/img/figure48.ead1f83f.png"},472:function(e,t,a){e.exports=a.p+"assets/img/figure49.9ea7487b.png"},473:function(e,t,a){e.exports=a.p+"assets/img/figure50.2a9e9169.png"},474:function(e,t,a){e.exports=a.p+"assets/img/figure51.15f0902e.png"},475:function(e,t,a){e.exports=a.p+"assets/img/figure52.edabae41.png"},476:function(e,t,a){e.exports=a.p+"assets/img/figure53.83c41d7b.png"},477:function(e,t,a){e.exports=a.p+"assets/img/figure54.9aa7463b.png"},478:function(e,t,a){e.exports=a.p+"assets/img/figure55.6c2f2dfe.png"},479:function(e,t,a){e.exports=a.p+"assets/img/figure133.b994be0a.png"},480:function(e,t,a){e.exports=a.p+"assets/img/figure134.828779b1.png"},481:function(e,t,a){e.exports=a.p+"assets/img/figure135.89f8b69b.png"},482:function(e,t,a){e.exports=a.p+"assets/img/figure137.8fcfaf0e.png"},483:function(e,t,a){e.exports=a.p+"assets/img/figure138.2be4b181.png"},532:function(e,t,a){"use strict";a.r(t);var s=a(54),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"storage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#storage"}},[e._v("#")]),e._v(" Storage")]),e._v(" "),s("h2",{attrs:{id:"csi-driver-architecture"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#csi-driver-architecture"}},[e._v("#")]),e._v(" CSI Driver Architecture")]),e._v(" "),s("p",[e._v("A diagrammatic representation of the CSI driver architecture is illustrated in the figure 10.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(447),alt:""}})]),e._v(" "),s("p",[s("strong",[e._v("Figure 10")]),e._v(": CSI Driver Architecture")]),e._v(" "),s("p",[e._v("The OpenShift Container Platform 4.9 cluster comprises the master and worker nodes (physical and virtual) with CoreOS deployed as the operating system. The iSCSI interface configured on the host nodes establishes the connection with the HPE 3PAR array to the cluster. Upon successful deployment of CSI Driver, the CSI controller, CSI Driver, and 3PAR CSP gets deployed which communicates with the HPE 3PAR array via REST APIs. The associated features on Storage Class such as CSI Provisioner, CSI Attacher, and others are configured on the Storage Class.")]),e._v(" "),s("h3",{attrs:{id:"configuring-csi-driver"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#configuring-csi-driver"}},[e._v("#")]),e._v(" Configuring CSI Driver")]),e._v(" "),s("p",[e._v("Prior to configuring the HPE CSI driver, the following Prerequisites needs to be met.")]),e._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[e._v("Prerequisites")]),e._v(" "),s("ol",[s("li",[e._v("OpenShift Container Platform 4.9 must be successfully deployed and console should be accessible.")]),e._v(" "),s("li",[e._v("iSCSI interface should be configured for HPE 3PAR Storage on Host server.")]),e._v(" "),s("li",[e._v("Additional iSCSI network interfaces must be configured on worker nodes (physical and virtual).")]),e._v(" "),s("li",[e._v("Deploy scc.yaml file to enable Security Context Constraints (SCC).")])])]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),s("p",[e._v("To get access to the host ports, host network, and to mount the host path volume, the HPE CSI Driver needs to be run in privileged mode. Prior to deployment of the CSI operator on OpenShift, create SCC to allow CSI driver to run with these privileges. Download SCC yaml file from GitHub "),s("a",{attrs:{href:"https://raw.githubusercontent.com/hpe-storage/co-deployments/master/operators/hpe-csi-operator/deploy/scc.yaml",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://raw.githubusercontent.com/hpe-storage/co-deployments/master/operators/hpe-csi-operator/deploy/scc.yaml"),s("OutboundLink")],1),e._v(" and update relevant fields such as project or namespace before running the yaml to deploy SCC.")])]),e._v(" "),s("h3",{attrs:{id:"configuring-iscsi-interface-on-worker-nodes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#configuring-iscsi-interface-on-worker-nodes"}},[e._v("#")]),e._v(" Configuring iSCSI interface on worker nodes")]),e._v(" "),s("p",[e._v("Additional iSCSI interface needs to be configured on all the worker nodes (physical and virtual) for establishing the connection between the OCP cluster and HPE 3PAR array. iSCSI_A and iSCSI_B interfaces needs to be configured on the worker nodes for redundancy. Follow the steps as listed to configure the additional interface.")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Create interface configuration files (ifcfg files) on each of the worker nodes by specifying the following parameters.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("HWADDR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("52")]),e._v(":4D:1F:20:01:94 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("MAC address of the iSCSI connector"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("TYPE")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("Ethernet\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("BOOTPROTO")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("none\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("IPADDR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("40.0")]),e._v(".17.221 \n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("PREFIX")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("16")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("DNS1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("20.1")]),e._v(".1.254\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("ONBOOT")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("yes\n")])])])]),e._v(" "),s("li",[s("p",[e._v("Reboot the worker nodes after configuring the ifcfg files. The 3PAR Discovery IP should be pingable.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(448),alt:""}})]),e._v(" "),s("p",[e._v("For virtual worker nodes, additional network adapters are added and the corresponding network port groups are selected.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(449),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"iscsi-interface-for-physical-worker-nodes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#iscsi-interface-for-physical-worker-nodes"}},[e._v("#")]),e._v(" iSCSI Interface for physical worker nodes")]),e._v(" "),s("p",[e._v("For physical worker nodes, iSCSI_A connection for storage interface and additional iSCSI_B connection is added for redundancy.")]),e._v(" "),s("h3",{attrs:{id:"steps-to-deploy-scc"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#steps-to-deploy-scc"}},[e._v("#")]),e._v(" Steps to deploy SCC")]),e._v(" "),s("p",[e._v("The following figure shows the parameters that needs to be edited (project name) where the CSI Operator is being deployed.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(450),alt:""}})]),e._v(" "),s("ol",[s("li",[s("p",[e._v("From the Installer vm, download the scc.yaml file from GitHub from\nthe following path. curl -sL\n"),s("a",{attrs:{href:"https://raw.githubusercontent.com/hpe-storage/co-deployments/master/operators/hpe-csi-operator/deploy/scc.yaml",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://raw.githubusercontent.com/hpe-storage/co-deployments/master/operators/hpe-csi-operator/deploy/scc.yaml"),s("OutboundLink")],1),e._v(" hpe-csi-scc.yaml")])]),e._v(" "),s("li",[s("p",[e._v("Edit relevant parameters such as Project name and save the file.")])]),e._v(" "),s("li",[s("p",[e._v("Deploy SCC and check the output")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc create -f hpe-csi-scc.yaml\n")])])]),s("p",[e._v("Output:")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("securitycontextconstraints.security.openshift.io/hpe-csi-scc created\n")])])])])]),e._v(" "),s("h2",{attrs:{id:"installing-hpe-csi-driver-on-an-existing-red-hat-openshift-container-platform"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-hpe-csi-driver-on-an-existing-red-hat-openshift-container-platform"}},[e._v("#")]),e._v(" Installing HPE CSI Driver on an existing Red Hat OpenShift Container Platform")]),e._v(" "),s("h3",{attrs:{id:"creating-namespace"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#creating-namespace"}},[e._v("#")]),e._v(" Creating Namespace")]),e._v(" "),s("p",[e._v("Before installing the CSI Driver from the OpenShift console, create a namespace called HPE-CSI Driver. Perform the following steps to create a Namespace.")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Click Administration → Namespaces in the left pane of the Console.")])]),e._v(" "),s("li",[s("p",[e._v("Click Create Namespaces.")])]),e._v(" "),s("li",[s("p",[e._v("In the Create Namespace dialogbox -> enter HPE- CSI.")])]),e._v(" "),s("li",[s("p",[e._v("Click Create.")])])]),e._v(" "),s("h3",{attrs:{id:"installing-red-hat-hpe-csi-driver-operator-using-the-operator-hub"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-red-hat-hpe-csi-driver-operator-using-the-operator-hub"}},[e._v("#")]),e._v(" Installing Red Hat HPE CSI Driver Operator using the Operator Hub")]),e._v(" "),s("h3",{attrs:{id:"installing-hpe-csi-driver-operator"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-hpe-csi-driver-operator"}},[e._v("#")]),e._v(" Installing HPE CSI Driver Operator")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Login to the Red Hat OpenShift Container Platform Web Console.")])]),e._v(" "),s("li",[s("p",[e._v("Click Operators → Operator Hub.")])]),e._v(" "),s("li",[s("p",[e._v("Search for HPE CSI Driver Operator from the list of operators and click HPE CSI Driver operator.")])]),e._v(" "),s("li",[s("p",[e._v("On the HPE-CSI Operator page, click Install.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(451),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("On the Create Operator Subscription page, the Installation Mode, Update Channel and Approval Strategy options are available.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(452),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("Select an Approval Strategy. The available options are:")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("Automatic: Specifies that the OpenShift Container Platform is required to upgrade HPE CSI")])]),e._v(" "),s("li",[s("p",[e._v("Storage automatically. Select the Automatic option.")])]),e._v(" "),s("li",[s("p",[e._v("Manual: Specifies that you need to upgrade to OpenShift Container Platform manually.")])])])]),e._v(" "),s("li",[s("p",[e._v("Click "),s("strong",[e._v("Subscribe")]),e._v(". The Installed Operators page is displayed with the status of the operator as shown.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(453),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"creating-hpe-csi-driver"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#creating-hpe-csi-driver"}},[e._v("#")]),e._v(" Creating HPE CSI driver")]),e._v(" "),s("p",[e._v("The HPE CSI Driver allows any vendor or project to develop its own Container Storage Provider by using the "),s("a",{attrs:{href:"https://developer.hpe.com/api/hpe-nimble-csp/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CSP specification"),s("OutboundLink")],1),e._v(". This makes it very easy for third- parties to integrate their storage solution into Kubernetes as all the intricacies are taken care of by the HPE CSI Driver.")]),e._v(" "),s("p",[e._v("To create HPE CSI driver, perform the following steps.")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Click Operators → Installed Operators from the left pane of the OpenShift Web Console to view the installed operators.")])]),e._v(" "),s("li",[s("p",[e._v("On the Installed Operator page, select HPE CSI Driver from the Project drop down list to switch to the HPE-CSI project")])]),e._v(" "),s("li",[s("p",[e._v("Click HPE CSI Driver.")])]),e._v(" "),s("li",[s("p",[e._v("On the HPE CSI Driver Operator page, scroll right and click the HPE CSI Driver yaml file.")])]),e._v(" "),s("li",[s("p",[e._v("Edit the HPE CSI Driver yaml file with required values like backend (3PAR array IP), password and username as shown.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(454),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("On the HPE CSI Driver Operator page, scroll right and click the HPECSI Driver tab as shown.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(455),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"verifying-creation-of-hpe-csi-driver"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#verifying-creation-of-hpe-csi-driver"}},[e._v("#")]),e._v(" Verifying creation of HPE CSI Driver")]),e._v(" "),s("p",[e._v("After the HPECSI Driver is deployed, one can see the associated deployment pods being created such as hpe-csi-controller, hpe-csi-driver, and primera3par-csp.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(456),alt:""}})]),e._v(" "),s("p",[e._v("To verify the HPE CSI Node Info, perform the following steps.")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Run the following command from the Installer VM to check HPENodeinfo and network status of worker nodes.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get HPENodeInfo\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get HPENodeInfo/"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("workernode fqdn"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" -o yaml\n")])])]),s("p",[s("img",{attrs:{src:a(457),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"hpe-csi-driver-storage-installation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hpe-csi-driver-storage-installation"}},[e._v("#")]),e._v(" HPE CSI Driver Storage installation")]),e._v(" "),s("p",[e._v("After installing HPE CSI Driver, Storage Class is created manually.")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("From the OpenShift console navigate to Storage -> Storage Class")])]),e._v(" "),s("li",[s("p",[e._v("Click Create Storage Class -> Click Edit yaml -> insert the parameters for SC creation -> Click Create.")])]),e._v(" "),s("li",[s("p",[e._v("'hpe-standard' storage class is created as shown.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(458),alt:""}})])])]),e._v(" "),s("p",[e._v("Run the following command on the CLI to tag the storage class default-storage class by :")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc annotate storageclass hpe-standard storageclass.kubernetes.io/is-default-class"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("true\n")])])]),s("p",[e._v("The create Storage Class yaml file parameters are as follows:")]),e._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[e._v("    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("apiVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" storage.k8s.io/v1\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("kind")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" StorageClass\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("metadata")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" hpe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("standard\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("provisioner")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" csi.hpe.com\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("parameters")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/fstype")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" ext4\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/controller-expand-secret-name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" primera3par"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secret\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/controller-expand-secret-namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" hpe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("csi\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/controller-publish-secret-name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" primera3par"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secret\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/controller-publish-secret-namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" hpe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("csi\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/node-publish-secret-name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" primera3par"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secret\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/node-publish-secret-namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" hpe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("csi\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/node-stage-secret-name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" primera3par"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secret\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/node-stage-secret-namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" hpe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("csi\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/provisioner-secret-name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" primera3par"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secret\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csi.storage.k8s.io/provisioner-secret-namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" hpe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("csi\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("cpg")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" SSD_r6 \n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("provisioning_type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" tpvv\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("accessProtocol")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" iscsi\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("reclaimPolicy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Delete\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("allowVolumeExpansion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[e._v("true")]),e._v("\n")])])]),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),s("p",[e._v("From the worker node, ssh to the 3PAR array to check on the cpg values for Storage Class creation as shown.")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(459),alt:""}})]),e._v(" "),s("h3",{attrs:{id:"sample-application-deployment"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sample-application-deployment"}},[e._v("#")]),e._v(" Sample application deployment")]),e._v(" "),s("p",[e._v("A sample application deployed on the existing Red Hat OpenShift Container Platform utilizes the volume from 3PAR array through HPE CSI Driver. A sample application such as mongodb or mariadb is deployed and scheduled on the worker nodes. Follow the steps to deploy a sample application.")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Run the following command to deploy a sample application.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc new-app mongodb-persistent\n")])])]),s("p",[s("img",{attrs:{src:a(460),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("Check the status of PVC and Pod.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(461),alt:""}})]),e._v(" "),s("p",[e._v("List of pods created on the cluster along with the one for sample application deployed is shown.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(462),alt:""}})]),e._v(" "),s("p",[e._v("PVC for the sample application deployed is created and bound. This can be verified in the OpenShift Console by navigating to Storage -> Persistent Volume Claim section.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(463),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"verification-of-persistent-volume-claim-on-3par-array"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#verification-of-persistent-volume-claim-on-3par-array"}},[e._v("#")]),e._v(" Verification of Persistent Volume Claim on 3PAR array")]),e._v(" "),s("p",[e._v("The PVC created for the sample application deployed (mongodb) can be verified on the 3PAR array by searching for the PVC id seen on the console or on the CLI.")]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),s("p",[e._v("The PVC ID is not completely seen on 3PAR console as it gets truncated beyond 30 characters.")])]),e._v(" "),s("p",[e._v("Steps to verify the PVC on 3PAR array:")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Login to the 3PAR SSMC URL at https://10.0.20.19:8443/#/login with appropriate credentials.")])]),e._v(" "),s("li",[s("p",[e._v("Navigate from the drop- down menu option on 3PAR StoreServ -> Virtual volumes")])]),e._v(" "),s("li",[s("p",[e._v("The volume for the PVC created can be seen under the list of virtual volume as shown.")])])]),e._v(" "),s("p",[s("img",{attrs:{src:a(464),alt:""}})]),e._v(" "),s("h3",{attrs:{id:"openshift-persistent-volume-expansion"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#openshift-persistent-volume-expansion"}},[e._v("#")]),e._v(" OpenShift Persistent Volume Expansion")]),e._v(" "),s("p",[e._v("The volume of the sample application deployed can be expanded by specifying the volume size on the OpenShift console. The steps for PVC expansion is as follows.")]),e._v(" "),s("ol",[s("li",[e._v("On the OpenShift web console navigate to Storage -> Persistent Volume Claims -> select a specific pod -> click on the dots seen towards the right side -> select 'Expand PVC'")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(465),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[s("p",[e._v("Change the volume size from 1Gi to 3Gi and click Expand button as shown.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(466),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("Now, you can see PVC and PV has been resized to 3 GB.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(467),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"csi-driver"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#csi-driver"}},[e._v("#")]),e._v(" CSI Driver")]),e._v(" "),s("p",[e._v("CSI was developed as a standard for exposing block and file storage systems to containerized workloads on Container Orchestrator Systems (COS) like Kubernetes. Container Storage Interface (CSI) is an initiative to unify the storage interface of COS combined with storage vendors. This means, implementing a single CSI for a storage vendor is guaranteed to work with all COS. With the introduction of CSI, there is a clear benefit for the COS and storage vendors. Due to its well-defined interfaces, it also helps developers and future COS to easily implement and test CSI. Volume plugins served the storage needs for container workloads in case of Kubernetes, before CSI existed. The HPE CSI Driver is a multi-vendor and multi-backend driver where each implementation has a Container Storage Provider (CSP). The HPE CSI Driver for Kubernetes uses CSP to perform data management operations on storage resources such as searching for a logical unit number (lun) and so on. Using the CSP specification, the HPE CSI Driver allows any vendor or project to develop its own CSP, which makes it very easy for third- parties to integrate their storage solution into Kubernetes as all the intricacies are taken care of by the HPE CSI Driver.")]),e._v(" "),s("p",[e._v("This document contains details on how to configure a HPE CSI Driver storage for 3PAR on an existing Red Hat OpenShift Container Platform 4.9.")]),e._v(" "),s("h2",{attrs:{id:"deploying-hpe-csi-driver-nimble-storage-on-ocp-4-9"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deploying-hpe-csi-driver-nimble-storage-on-ocp-4-9"}},[e._v("#")]),e._v(" Deploying HPE CSI Driver Nimble Storage on OCP 4.9")]),e._v(" "),s("h3",{attrs:{id:"configuring-iscsi-interface-on-worker-nodes-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#configuring-iscsi-interface-on-worker-nodes-2"}},[e._v("#")]),e._v(" Configuring iSCSI interface on worker nodes")]),e._v(" "),s("p",[e._v("Additional iSCSI interface needs to be configured on all the worker nodes (physical and virtual) for establishing the connection between the OCP cluster and HPE Nimble array. iSCSI_A and iSCSI_B interfaces needs to be configured on the worker nodes for redundancy.")]),e._v(" "),s("p",[e._v("Follow the steps as- listed to configure the additional interface.")]),e._v(" "),s("ol",[s("li",[e._v("Create interface configuration files (ifcfg files) on each of the worker nodes by specifying the following parameters.")])]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("HWADDR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("52")]),e._v(":4D:1F:20:01:94 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("MAC address of the iSCSI connector"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("TYPE")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("Ethernet\n    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("BOOTPROTO")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("none\n    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("IPADDR")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("40.0")]),e._v(".17.221 \n    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("PREFIX")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("16")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("DNS1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("20.1")]),e._v(".1.254\n    "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e._v("ONBOOT")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("yes\n")])])]),s("ol",{attrs:{start:"2"}},[s("li",[s("p",[e._v("Reboot the worker nodes after configuring the ifcfg files. The Nimble Discovery IP should be pingable.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(468),alt:""}})]),e._v(" "),s("p",[e._v("For virtual worker nodes, additional Network adapters are added and the corresponding network port groups are selected.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(469),alt:""}})])])]),e._v(" "),s("h3",{attrs:{id:"iscsi-interface-for-physical-worker-nodes-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#iscsi-interface-for-physical-worker-nodes-2"}},[e._v("#")]),e._v(" iSCSI Interface for Physical worker nodes")]),e._v(" "),s("p",[e._v("For Physical worker nodes, iSCSI_A connection for storage interface and additional iSCSI_B connection is added for redundancy.")]),e._v(" "),s("p",[e._v("network connection screenshot needs to be added")]),e._v(" "),s("h3",{attrs:{id:"openshift-persistent-volume-expansion-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#openshift-persistent-volume-expansion-2"}},[e._v("#")]),e._v(" OpenShift Persistent Volume Expansion")]),e._v(" "),s("p",[e._v("The volume of the sample application deployed can be expanded by specifying the volume size on the OpenShift console. The steps for PVC expansion is listed as follows.")]),e._v(" "),s("ol",[s("li",[e._v("On the OpenShift web console navigate to Storage -> Persistent Volume Claims -> select a specific pod -> click on the dots seen towards the right side -> select 'Expand PVC'")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(470),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[e._v("Change the volume size from 1Gi to 3Gi and click Expand button.")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(471),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[e._v("Now you can see PVC and PV has been resized to 3 GB.")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(472),alt:""}})]),e._v(" "),s("h2",{attrs:{id:"deploying-openshift-data-foundation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deploying-openshift-data-foundation"}},[e._v("#")]),e._v(" Deploying Openshift Data Foundation")]),e._v(" "),s("p",[e._v("This section covers deploying OpenShift Data Foundation 4.8 on existing Red Hat OpenShift Container Platform 4.9 worker nodes.")]),e._v(" "),s("p",[e._v("The OpenShift Data Foundation operator installation will be using Local Storage operator which will use file system storage of 10GB for monitoring purpose and block storage of 500GB/2TB for OSD (Object Storage Daemon) volumes. These OSD are useful for configuring any application on top of OCP cluster using ODF configuration.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(473),alt:""}})]),e._v(" "),s("p",[s("strong",[e._v("Figure 11.")]),e._v(" Logical storage Layout in Solution")]),e._v(" "),s("p",[e._v("The below operators are required to create ODF cluster and deployed through automation fashion.")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("Local Storage Operator")])]),e._v(" "),s("li",[s("p",[e._v("OpenShift Data Foundation Operator")])])]),e._v(" "),s("h3",{attrs:{id:"flow-diagram"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#flow-diagram"}},[e._v("#")]),e._v(" Flow Diagram")]),e._v(" "),s("p",[s("img",{attrs:{src:a(474),alt:""}})]),e._v(" "),s("p",[s("strong",[e._v("Figure 12")]),e._v(". Deploying OpenShift Data Foundation Solution Flow Diagram")]),e._v(" "),s("h3",{attrs:{id:"configuration-requirements"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#configuration-requirements"}},[e._v("#")]),e._v(" Configuration requirements")]),e._v(" "),s("p",[e._v("The below table shows about all required worker node configuration.")]),e._v(" "),s("table",[s("thead",[s("tr",[s("th",[s("strong",[e._v("Server Role")])]),e._v(" "),s("th",[s("strong",[e._v("CPU")])]),e._v(" "),s("th",[s("strong",[e._v("RAM")])]),e._v(" "),s("th",[s("strong",[e._v("HardDisk1")])]),e._v(" "),s("th",[s("strong",[e._v("HardDiak2")])]),e._v(" "),s("th",[s("strong",[e._v("HardDisk3")])])])]),e._v(" "),s("tbody",[s("tr",[s("td",[e._v("Worker")]),e._v(" "),s("td",[e._v("16")]),e._v(" "),s("td",[e._v("64")]),e._v(" "),s("td",[e._v("120 GB")]),e._v(" "),s("td",[e._v("10 GB")]),e._v(" "),s("td",[e._v("500 GB/2 TB")])])])]),e._v(" "),s("h3",{attrs:{id:"pre-requisites"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pre-requisites"}},[e._v("#")]),e._v(" Pre-requisites")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Red Hat OpenShift Container Platform 4.9 cluster console is required with the login credentials.")])]),e._v(" "),s("li",[s("p",[e._v("Availability of any local storage from any storage (i.e Nimble,3PAR,Local Storage) in OpenShift Container Platform.")])]),e._v(" "),s("li",[s("p",[e._v('ODF installation on OCP 4.9 cluster requires a minimum of 3 worker nodes but ODF should have exact 3 worker nodes which use two more hard disks with 10GB for mon POD (3 in total using always a PVC) + 500GB (or more than 500GB) volume (a PVC using the default "'),s("strong",[e._v("thin")]),e._v('" storage class) for the OSD volumes. It also requires 16 CPUs and 64GB RAM for each node and worker node hard disk configuration as shown in above figure.')])])]),e._v(" "),s("h3",{attrs:{id:"scripts-for-deploying-odf-cluster"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#scripts-for-deploying-odf-cluster"}},[e._v("#")]),e._v(" Scripts for deploying ODF cluster")]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),s("p",[e._v("BASE_DIR - is a base directory path for all automated scripts directories are in place and path is\n/opt/hpe/solutions/ocp/hpe-solutions-openshift/DL/scalable")])]),e._v(" "),s("p",[e._v("This section provides details on the scripts developed to automate the installation of ODF operator on the OCP cluster. The scripts used to deploy ODF can be found in the installer VM at "),s("em",[e._v("$BASE_DIR/ocs_installation")]),e._v(".")]),e._v(" "),s("ol",[s("li",[s("p",[s("strong",[e._v("install_odf_operator.py")]),e._v(" - main python script which installs Local Storage operator, OpenShift Data Foundation operators, creates file system & block storage and also creates SCs, PVs, PVCs.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("config.py")]),e._v(" - This python script is used to convert user input values into program variables for usage by the install_odf_operator.py script.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("userinput.json")]),e._v(" - The userinput.json file needs to be modified as per user configuration and requirements for installing and scaling ODF cluster.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("config_secrets.json")]),e._v(" -- This encrypted file has OCP cluster login credentials and user needs to provide credentials to this file using 'ansible-vault' command.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("create_local_storage_operator.yaml")]),e._v(" -- Creates Local Storage operator's Namespace, installs Local Storage operator.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("local_storage_fs.yaml")]),e._v(" -- Creates file system storage for monitoring ODF cluster.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("local_storage_block.yaml")]),e._v(" -- Creates block storage for claiming OSD persistent volumes.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("odf_operator.yaml")]),e._v(" -- This playbook creates OpenShift Data Foundation Namespace, block storage for bounding PVC to Storage Class.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("storage_odf.yaml")]),e._v(" -- This playbook creates storage classes, PVCs, pods to bring up the ODF cluster.")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("scaling_odf_operator.py -")]),e._v(" This python script is used to scale ODF cluster by expanding ODF storage with 3 more worker nodes.")])])]),e._v(" "),s("h2",{attrs:{id:"installing-openshift-data-foundation-on-openshift-container-platform"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-openshift-data-foundation-on-openshift-container-platform"}},[e._v("#")]),e._v(" Installing OpenShift Data Foundation on OpenShift Container Platform")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Login to the installer machine as non-root user and browse to python virtual environment as per DG.")])]),e._v(" "),s("li",[s("p",[e._v("Update the "),s("em",[e._v("config_secrets.json")]),e._v(" file found at "),s("em",[e._v("$BASE_DIR/ocs_installation")]),e._v(" using 'ansible-vault' command as shown below:")]),e._v(" "),s("p",[e._v("The below command is used to open encrypted file config_secrets.json")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" ansible-vault edit config_secrets.json\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" OPENSHIFT_USERNAME: "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("OpenShift Container Platform cluster username"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" OPENSHIFT_PASSWORD: "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("OpenShift Container Platform cluster password"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n")])])])]),e._v(" "),s("li",[s("p",[e._v("Update the "),s("em",[e._v("userinput.json")]),e._v(" file is found at "),s("em",[e._v("$BASE_DIR/ocs_installation")]),e._v(" with the following setup configuration details:")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("OPENSHIFT_DOMAIN: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<OpenShift Server sub domain fqdn (api.domain.base_domain)>"')]),e._v(",\n\nOPENSHIFT_PORT: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<OpenShift Server port number (OpenShift Container Platform runs on port 6443 by default)>"')]),e._v(",\n\nLOCAL_STORAGE_NAMESPACE: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<Local Storage Operator Namespace (local-storage)>"')]),e._v(",\n\nOPENSHIFT_CONTAINER_STORAGE_NAMESPACE: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<OpenShift Container Storage Operator Namespace (openshift-storage)>"')]),e._v(",\n\nOPENSHIFT_CONTAINER_STORAGE_LOCAL_STORAGE_VERSION:"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<OCP_cluster_version>"')]),e._v(",\n\nOPENSHIFT_CONTAINER_STORAGE_FILESYSTEM_STORAGE: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<Provide 10GiB worker node\'s drive for file system storage (Ex: /dev/sdb)>"')]),e._v(" ,\n\nOPENSHIFT_CONTAINER_STORAGE_BLOCK_STORAGE: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<Provide 500Gi worker node\'s drive for block storage (Ex: /dev/sdc)>"')]),e._v(",\n\nOPENSHIFT_CLIENT_PATH: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<Provide oc absolute path ending with / OR leave empty in case oc is available under /usr/local/bin>"')]),e._v(",\n\n"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"OPENSHIFT_CONTAINER_PLATFORM_WORKER_NODES"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("Provide OCP worker nodes fqdn list "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"sworker1.fqdn"')]),e._v(", "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"sworker2.fqdn"')]),e._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"worker3.fqdn"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(",\n\n"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"OPENSHIFT_CONTAINER_STORAGE_SCALING_WORKER_NODES"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("Provide OCS worker nodes fqdn list "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"sworker4.fqdn"')]),e._v(", "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"sworker5.fqdn"')]),e._v(", "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"sworker6.fqdn"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(",\n\n"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"OPENSHIFT_CONTAINER_STORAGE_BLOCK_VOLUME"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<Provide base/scale OCS worker node block storage, should be in Gi/Ti (example 500Gi or 2Ti)>"')]),e._v("\n")])])])]),e._v(" "),s("li",[s("p",[e._v("Execute the following command to deploy ODF cluster.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("cd")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$BASE_DIR")]),e._v("/odf_installation\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" python -W ignore install_odf_operator.py\n")])])]),s("p",[e._v("The output of the above command as shown below:")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" python -W ignore install_odf_operator.py\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("Enter key "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" encrypted variables:\n\nLogging into your OpenShift Cluster\n\nSuccessfully logged into the OpenShift Cluster\n\nWaiting "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v(" minutes to "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'Local Storage'")]),e._v(" operator to be available on OCP web console"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("..")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),e._v("\n\n"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'Local Storage'")]),e._v(" operator is created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("..")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),e._v("\n\nWaiting "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("2")]),e._v(" minutes to ODF operator to be available on OCP web console"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("..")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),e._v("\n\n"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'OpenShift Data Foundation'")]),e._v(" operator is created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("..")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("!")]),e._v("\n\nINFO:\n\n"),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" Run the below "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("command")]),e._v(" to list all PODs and PVCs of ODF cluster.\n\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'oc get pod,pvc -n openshift-storage'")]),e._v("\n\n"),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" Wait "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'pod/ocs-operator-xxxx'")]),e._v(" pod to be up and running.\n\n"),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" Log into OCP web GUI and check Persistant Stoarge "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("in")]),e._v(" dashboard.\n\n$\n")])])])])]),e._v(" "),s("h2",{attrs:{id:"validation-of-the-openshift-data-foundation-cluster"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validation-of-the-openshift-data-foundation-cluster"}},[e._v("#")]),e._v(" Validation of the OpenShift Data Foundation cluster")]),e._v(" "),s("p",[e._v("The required operators will be created after the execution of the script and they will be reflected in the OpenShift console. This section outlines the steps to verify the operators created through script and are reflected in the GUI:")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Login to the "),s("strong",[e._v("OpenShift Container Platform")]),e._v(" web console as the user with administrative privileges.")])]),e._v(" "),s("li",[s("p",[e._v("Navigate to "),s("strong",[e._v("Operators -> Project (local-storage)")]),e._v(" -> "),s("strong",[e._v("Installed")]),e._v(" "),s("strong",[e._v("Operators")]),e._v(" select your project name.")])]),e._v(" "),s("li",[s("p",[e._v("The Openshift data foundation operator will be available in the OpenShift web console as shown in below Figure.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(475),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("Navigate to "),s("strong",[e._v("Operators")]),e._v(" -> "),s("strong",[e._v("Installed")]),e._v(" "),s("strong",[e._v("Operators")]),e._v(" select your project name openshift-storage for OpenShift Data Foundation operator.")])]),e._v(" "),s("li",[s("p",[e._v("The OpenShift Data Foundation operator will be available on the OpenShift Container Platform web console as shown in below Figure.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(476),alt:""}})])]),e._v(" "),s("li",[s("p",[e._v("SCs of OpenShift Data Foundation operator on CLI as shown in below.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get sc\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME                          PROVISIONER                             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nlocal-sc                      kubernetes.io/no-provisioner            Delete          WaitForFirstConsumer   "),s("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("false")]),e._v("                  45h\nlocalblock-sc                 kubernetes.io/no-provisioner            Delete          WaitForFirstConsumer   "),s("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("false")]),e._v("                  45h\nodf-storagecluster-ceph-rbd   openshift-storage.rbd.csi.ceph.com      Delete          Immediate              "),s("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("false")]),e._v("                  45h\nodf-storagecluster-cephfs     openshift-storage.cephfs.csi.ceph.com   Delete          Immediate              "),s("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("false")]),e._v("                  45h\nopenshift-storage.noobaa.io   openshift-storage.noobaa.io/obc         Delete          Immediate              "),s("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("false")]),e._v("                  45h\n")])])])]),e._v(" "),s("li",[s("p",[e._v("PVs of OpenShift Data Foundation operator on CLI as shown in\nbelow.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get "),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("pv")]),e._v("\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                       STORAGECLASS                  REASON   AGE\nlocal-pv-2febb788                          500Gi      RWO            Delete           Bound    openshift-storage/odf-deviceset-1-0-lhtvh   localblock-sc                          45h\nlocal-pv-5f19c0e5                          10Gi       RWO            Delete           Bound    openshift-storage/rook-ceph-mon-b           local-sc                               45h\nlocal-pv-b73b1cd5                          500Gi      RWO            Delete           Bound    openshift-storage/odf-deviceset-2-0-jmmck   localblock-sc                          45h\nlocal-pv-b8ba8c38                          10Gi       RWO            Delete           Bound    openshift-storage/rook-ceph-mon-a           local-sc                               45h\nlocal-pv-c3a372f6                          10Gi       RWO            Delete           Bound    openshift-storage/rook-ceph-mon-c           local-sc                               45h\nlocal-pv-e5e3d596                          500Gi      RWO            Delete           Bound    openshift-storage/odf-deviceset-0-0-5jxg7   localblock-sc                          45h\npvc-8f3e3d8b-6be7-4ba8-8968-69cbc866c89f   50Gi       RWO            Delete           Bound    openshift-storage/db-noobaa-db-0            ocs-storagecluster-ceph-rbd            45h\n $\n")])])])]),e._v(" "),s("li",[s("p",[e._v("PVCs of OpenShift Data Foundation operator on CLI as shown in below.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get pvc -n openshift-storage\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                  AGE\ndb-noobaa-db-0            Bound    pvc-8f3e3d8b-6be7-4ba8-8968-69cbc866c89f   50Gi       RWO            odf-storagecluster-ceph-rbd   45h\nodf-deviceset-0-0-5jxg7   Bound    local-pv-e5e3d596                          500Gi      RWO            localblock-sc                 45h\nodf-deviceset-1-0-lhtvh   Bound    local-pv-2febb788                          500Gi      RWO            localblock-sc                 45h\nodf-deviceset-2-0-jmmck   Bound    local-pv-b73b1cd5                          500Gi      RWO            localblock-sc                 45h\nrook-ceph-mon-a           Bound    local-pv-b8ba8c38                          10Gi       RWO            local-sc                      45h\nrook-ceph-mon-b           Bound    local-pv-5f19c0e5                          10Gi       RWO            local-sc                      45h\nrook-ceph-mon-c           Bound    local-pv-c3a372f6                          10Gi       RWO            local-sc                      45h\n $\n")])])])]),e._v(" "),s("li",[s("p",[e._v("PODs of OpenShift Data Foundation operator on CLI as shown in below.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get pod -n openshift-storage\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME READY STATUS RESTARTS AGE\n\ncsi-cephfsplugin-6xpsk "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-cephfsplugin-7khm6 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 17m\n\ncsi-cephfsplugin-bb48n "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-cephfsplugin-cfzx6 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 15m\n\ncsi-cephfsplugin-provisioner-79587c64f9-2dpm6 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("5")]),e._v("/5 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-cephfsplugin-provisioner-79587c64f9-hf46x "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("5")]),e._v("/5 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-cephfsplugin-w6p6v "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-rbdplugin-2z686 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-rbdplugin-6tv5m "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-rbdplugin-jgf5z "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 17m\n\ncsi-rbdplugin-provisioner-5f495c4566-76rqm "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("5")]),e._v("/5 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-rbdplugin-provisioner-5f495c4566-pzvww "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("5")]),e._v("/5 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-rbdplugin-v7lfx "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\ncsi-rbdplugin-ztdjs "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 15m\n\nnoobaa-core-0 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nnoobaa-db-0 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nnoobaa-endpoint-6458fc874f-vpznd "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nnoobaa-operator-7f4495fc6-lmk9k "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nodf-operator-5d664769f-59v8j "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-crashcollector-sworker1.socp.twentynet.local-84dddddb "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-crashcollector-sworker2.socp.twentynet.local-8b5qzzsz "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-crashcollector-sworker3.socp.twentynet.local-699n9kzp "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-drain-canary-sworker1.socp.twentynet.local-85bffzm66m "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-drain-canary-sworker2.socp.twentynet.local-66bcfjjfkr "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-drain-canary-sworker3.socp.twentynet.local-5f6b57c9nt "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-mds-ocs-storagecluster-cephfilesystem-a-67fbb67dkb4kz "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-mds-ocs-storagecluster-cephfilesystem-b-db66df7dtqkmx "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-mgr-a-6f5f7b58dc-fjvjc "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-mon-a-76cc49c944-5pcgf "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-mon-b-b9449cdd7-s6mct "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-mon-c-59d854cd8-gn6sd "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-operator-775cd6cd66-sdfph "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-osd-0-7644557bfb-9l7ns "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-osd-1-7694c74948-lc9sf "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-osd-2-794547558-wjcpz "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-osd-prepare-ocs-deviceset-0-0-5jxg7-t89zh "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("/1 Completed "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-osd-prepare-ocs-deviceset-1-0-lhtvh-f2znl "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("/1 Completed "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-osd-prepare-ocs-deviceset-2-0-jmmck-wsrb2 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("/1 Completed "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\nrook-ceph-rgw-ocs-storagecluster-cephobjectstore-a-67b7865qx276 "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1 Running "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v(" 45h\n\n$\n")])])])]),e._v(" "),s("li",[s("p",[e._v("Storage capacity of ODF cluster with 3 worker nodes (3x500Gi) on OCP web cluster as shown below figure.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(477),alt:""}})])])]),e._v(" "),s("h2",{attrs:{id:"validating-odf-with-deploying-wordpress-application"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-odf-with-deploying-wordpress-application"}},[e._v("#")]),e._v(" Validating ODF with deploying WordPress application")]),e._v(" "),s("p",[e._v("This section covers the steps to validate the OpenShift Data Foundation deployment (ODF) by deploying 2-tier application along with MySQL database.")]),e._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[e._v("Prerequisites")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("OCP 4.9 cluster must be installed.")])]),e._v(" "),s("li",[s("p",[e._v("ODF to claim persistent volume (PV).")])])])]),e._v(" "),s("h3",{attrs:{id:"deploying-wordpress-application"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deploying-wordpress-application"}},[e._v("#")]),e._v(" Deploying WordPress application")]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),s("p",[e._v("BASE_DIR - is a base directory path for all automated scripts directories are in place and path is\n/opt/hpe/solutions/ocp/hpe-solutions-openshift/DL/scalable")])]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Login to the installer machine as a non-root user.")])]),e._v(" "),s("li",[s("p",[e._v("From within the repository, navigate to the WordPress script folder")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("cd")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$BASE_DIR")]),e._v("/ocs_installation/wordpress\n")])])])]),e._v(" "),s("li",[s("p",[e._v("Run below script to deploy Wordpress application along with MySQL")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" ./deploy_wordpress.sh\n")])])])])]),e._v(" "),s("p",[e._v("The deploy_wordpress.sh scripts does the following activities.")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("Creates project")])]),e._v(" "),s("li",[s("p",[e._v("Sets default storage class")])]),e._v(" "),s("li",[s("p",[e._v("Deploys Wordpress and MySQL app")])]),e._v(" "),s("li",[s("p",[e._v("Create routes")])])]),e._v(" "),s("ol",{attrs:{start:"6"}},[s("li",[s("p",[e._v("Below is the output of the scripts")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" ./deploy_wordpress.sh\n")])])]),s("p",[e._v("Output of the command follows:")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("Already on project "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"wordpress"')]),e._v(" on server "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"https://api.socp.twentynet.local:6443"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(".")]),e._v("\n\nYou can "),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("add")]),e._v(" applications to this project with the "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'new-app'")]),e._v(" command.\nFor example, try:\n\noc new-app ruby~https://github.com/sclorg/ruby-ex.git\n\nto build a new example application "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("in")]),e._v(" Ruby. Or use kubectl to deploy a simple Kubernetes application:\n\nkubectl create deployment hello-node --image"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v("gcr.io/hello-minikube-zero-install/hello-node\n\nAlready on project "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"wordpress"')]),e._v(" on server "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"https://api.socp.twentynet.local:6443"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(".")]),e._v("\n\nclusterrole.rbac.authorization.k8s.io/system:openshift:scc:anyuid\nadded: "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"default"')]),e._v("error: --overwrite is "),s("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("false")]),e._v(" but found the following declared annotation"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(":\n"),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'storageclass.kubernetes.io/is-default-class'")]),e._v(" already has a value "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("true"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n\nservice/wordpress-http created\n\nservice/wordpress-mysql created\n\npersistentvolumeclaim/mysql-pv-claim created\n\npersistentvolumeclaim/wp-pv-claim created\n\nsecret/mysql-pass created\n\ndeployment.apps/wordpress-mysql created\n\ndeployment.apps/wordpress created\n\nroute.route.openshift.io/wordpress-http created\n\nURL to access application\n\nwordpress-http-wordpress.apps.socp.twentynet.local\n\n$\n")])])])])]),e._v(" "),s("h2",{attrs:{id:"verifying-the-wordpress-deployment"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#verifying-the-wordpress-deployment"}},[e._v("#")]),e._v(" Verifying the WordPress deployment")]),e._v(" "),s("ol",[s("li",[s("p",[e._v("Execute the following command to verify the persistent volume associated with WordPress application and MySQL database.")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get pods,pvc,route -n wordpress\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME                                  READY   STATUS    RESTARTS   AGE\npod/wordpress-6f69797b8f-hqpss        "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          5m52s\npod/wordpress-mysql-8f4b599b5-cd2s2   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          5m52s\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                  AGE\npersistentvolumeclaim/mysql-pv-claim   Bound    pvc-ccf2a578-9ba3-4577-8115-7c80ac200a9c   5Gi        RWO            ocs-storagecluster-ceph-rbd   5m50s\npersistentvolumeclaim/wp-pv-claim      Bound    pvc-3acec0a0-943d-4138-bda9-5b57f8c35c5d   5Gi        RWO            ocs-storagecluster-ceph-rbd   5m50s\n")])])]),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[e._v("NAME                                      HOST/PORT                                              "),s("span",{pre:!0,attrs:{class:"token environment constant"}},[e._v("PATH")]),e._v("   SERVICES         PORT     TERMINATION   WILDCARD\nroute.route.openshift.io/wordpress-http   wordpress-http-wordpress.apps.socp.twentynet.local          wordpress-http   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("80")]),e._v("-tcp                 None\n$\n")])])])]),e._v(" "),s("li",[s("p",[e._v("Access the route url in browser to access the WordPress application as shown below.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(478),alt:""}})])])]),e._v(" "),s("h2",{attrs:{id:"deploying-openshift-data-foundation-with-vmware-vsphere"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deploying-openshift-data-foundation-with-vmware-vsphere"}},[e._v("#")]),e._v(" Deploying OpenShift Data Foundation with VMware vSphere")]),e._v(" "),s("p",[e._v("OpenShift 4.9 provides software-defined storage that is optimized for container environment. OpenShift Data Foundation (ODF) can either be deployed on vSphere or AWS Azure.")]),e._v(" "),s("p",[e._v("For more information on planning your infrastructure requirements for ODF, see\n(https://access.redhat.com/documentation/en-us/red_hat_openshift_container_storage/4.8/pdf/planning_your_deployment/Red_Hat_OpenShift_Container_Storage-4.8-Planning_your_deployment-en-US.pdf)")]),e._v(" "),s("p",[e._v("Use the Red Hat ®OpenShift ®Container Platform operator hub to install ODF on vSphere Platform. For more information on how to install ODF on vSphere using Red Hat OpenShift Container Platform, see\n("),s("a",{attrs:{href:"https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.9/html/deploying_openshift_data_foundation_on_vmware_vsphere/index",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.9/html/deploying_openshift_data_foundation_on_vmware_vsphere/index"),s("OutboundLink")],1),e._v(") # CSI Driver Prior to Container Storage Integration (CSI), Kubernetes provided in-tree plugins to support volume. This posed a problem as\nstorage vendors had to align to the Kubernetes release process to fix a bug or to release new features. This also means every storage vendor had their own process to present volume to Kubernetes.")]),e._v(" "),s("h2",{attrs:{id:"hpe-ezmeral-data-fabric-csi-operator-integration-with-openshift"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hpe-ezmeral-data-fabric-csi-operator-integration-with-openshift"}},[e._v("#")]),e._v(" HPE Ezmeral Data Fabric CSI Operator Integration with OpenShift")]),e._v(" "),s("h3",{attrs:{id:"installing-the-hpe-ezmeral-csi-operator"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-the-hpe-ezmeral-csi-operator"}},[e._v("#")]),e._v(" Installing the HPE Ezmeral CSI Operator")]),e._v(" "),s("h3",{attrs:{id:"overview"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#overview"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),s("p",[e._v("The HPE Ezmeral CSI Operator for Kubernetes packages, deploys, and manages HPE Ezmeral CSI Drivers on OpenShift. After installing the operator and creating a CSI Driver object, you can enable static and dynamic provisioning of persistent volumes on the HPE Ezmeral Data Fabric platform.\nFlow Diagram")]),e._v(" "),s("p",[s("img",{attrs:{src:a(479),alt:""}})]),e._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[e._v("Pre-requisites")]),e._v(" "),s("ul",[s("li",[e._v("Red Hat OpenShift Container Platform 4.9 cluster console is required with the login credentials.")]),e._v(" "),s("li",[e._v("HPE Ezmeral Data Fabric CSI Version 6.2.0 cluster required a minimum of 5 nodes each node required minimum of 16 GB, more in production, For additional disk Raw, unformatted drives and no partitions. Please review the Installer Prerequisites and Guidelines,")])])]),e._v(" "),s("h3",{attrs:{id:"installing-the-operator-using-the-openshift-web-console"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-the-operator-using-the-openshift-web-console"}},[e._v("#")]),e._v(" Installing the Operator Using the OpenShift Web Console")]),e._v(" "),s("h3",{attrs:{id:"creating-namespace-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#creating-namespace-2"}},[e._v("#")]),e._v(" Creating Namespace")]),e._v(" "),s("p",[e._v("Before installing the CSI Driver from the OpenShift console, create a namespace called HPE-CSI Driver. Perform the following steps to create a Namespace.")]),e._v(" "),s("ol",[s("li",[e._v("Click Administration → Namespaces in the left pane of the Console.")]),e._v(" "),s("li",[e._v("Click Create Namespaces.")]),e._v(" "),s("li",[e._v("In the Create Namespace dialogbox -> enter hpe-ezmeral-csi")]),e._v(" "),s("li",[e._v("Click Create")])]),e._v(" "),s("h3",{attrs:{id:"installing-hpe-ezmeral-data-fabric-csi-operator-using-the-operator-hub"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#installing-hpe-ezmeral-data-fabric-csi-operator-using-the-operator-hub"}},[e._v("#")]),e._v(" Installing Hpe Ezmeral Data Fabric CSI Operator using the Operator Hub")]),e._v(" "),s("ol",[s("li",[e._v("Once the SCC has been applied to the project, log in to the OpenShift web console as kube:admin, and navigate to Operators > OperatorHub.")]),e._v(" "),s("li",[e._v("In the search field, type HPE Ezmeral, and press enter:")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(480),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[e._v("Select the HPE Ezmeral Data Fabric CSI Operator for Kubernetes and click Install:")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(481),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"4"}},[s("li",[e._v("In the next pane, click Install")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(359),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"5"}},[s("li",[e._v("The HPE Ezmeral CSI Operator is now installed:")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(482),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"6"}},[s("li",[e._v("Click the HPE Ezmeral Data Fabric CSI Operator for Kubernetes to view the Operator Details:")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(483),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"7"}},[s("li",[e._v("To create the HPE Ezmeral CSI Driver (NFS), click Create Instance under HPEEzmeralNFSCSIDriver.")]),e._v(" "),s("li",[e._v("In the Create HPEEzmeralNFSCSIDriver pane, click Create")])]),e._v(" "),s("p",[s("img",{attrs:{src:a(359),alt:""}})]),e._v(" "),s("ol",{attrs:{start:"9"}},[s("li",[e._v("Verify that HPE Ezmeral CSI Operator and CSI Driver pods are running in the namespace")])]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc get pods -n hpe-ezmeral-csi\nNAME                                            READY    STATUS    RESTARTS   AGE\nhpe-ezmeral-csi-controller-0                     "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("7")]),e._v("/7     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          62s\nhpe-ezmeral-csi-driver-operator-9dd887bf7-hdxc9  "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v("/1     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          4m6s\nhpe-ezmeral-csi-node-79xw5                       "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          61s\nhpe-ezmeral-csi-node-m2gpv                       "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          61s\nhpe-ezmeral-csi-node-x25dr                       "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          61s\nhpe-ezmeral-nfscsi-controller-0                  "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("7")]),e._v("/7     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          29s\nhpe-ezmeral-nfscsi-node-hhrhv                    "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          28s\nhpe-ezmeral-nfscsi-node-jz5cx                    "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          28s\nhpe-ezmeral-nfscsi-node-tvtgm                    "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),e._v("/3     Running   "),s("span",{pre:!0,attrs:{class:"token number"}},[e._v("0")]),e._v("          28s\n\n")])])]),s("p",[e._v("The CSI Driver is now ready for use. To use the CSI Driver to statically and dynamically provision and mount a data-fabric volume.")]),e._v(" "),s("h3",{attrs:{id:"configuring-dynamic-provisioning-using-container-storage-interface-csi-storage-plugin"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#configuring-dynamic-provisioning-using-container-storage-interface-csi-storage-plugin"}},[e._v("#")]),e._v(" Configuring Dynamic Provisioning Using Container Storage Interface (CSI) Storage Plugin")]),e._v(" "),s("h3",{attrs:{id:"configuring-a-secret"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#configuring-a-secret"}},[e._v("#")]),e._v(" Configuring a Secret")]),e._v(" "),s("h3",{attrs:{id:"rest-secrets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rest-secrets"}},[e._v("#")]),e._v(" REST Secrets")]),e._v(" "),s("p",[e._v("For dynamic provisioning, you must use a Secret to pass the user name and password of a data-fabric user to the provisioner. This user must have privileges to create and delete a data-fabric volume. The credentials allow the provisioner to make REST calls to the data-fabric webserver. Secrets are protected by the Kubernetes RBAC.\nThe following example shows a REST secret in the Secret file:")]),e._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("apiVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" v1\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("kind")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Secret\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("metadata")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" mapr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("provisioner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secrets\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("driver\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Opaque\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("data")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("MAPR_CLUSTER_USER")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" cm9vdA==\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("MAPR_CLUSTER_PASSWORD")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" bWFwcg==             \n")])])]),s("p",[e._v("The following table describes the REST secret fields in the REST Secret example.")]),e._v(" "),s("table",[s("thead",[s("tr",[s("th",[e._v("Parameter")]),e._v(" "),s("th",[e._v("Notes")])])]),e._v(" "),s("tbody",[s("tr",[s("td",[e._v("MAPR_CLUSTER_USER")]),e._v(" "),s("td",[e._v("The base64 representation of a data-fabric user that has the ability    to create and delete data-fabric volumes. See Converting a String to Base64("),s("a",{attrs:{href:"https://docs.datafabric.hpe.com/62/PersistentStorage/kdf_converting_a_string.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://docs.datafabric.hpe.com/62/PersistentStorage/kdf_converting_a_string.html"),s("OutboundLink")],1),e._v(").")])]),e._v(" "),s("tr",[s("td",[e._v("MAPR_CLUSTER_PASSWORD")]),e._v(" "),s("td",[e._v("The base64 representation of the password for the user defined by the MAPR_CLUSTER_USER parameter. See .Converting a String to Base64("),s("a",{attrs:{href:"https://docs.datafabric.hpe.com/62/PersistentStorage/kdf_converting_a_string.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://docs.datafabric.hpe.com/62/PersistentStorage/kdf_converting_a_string.html"),s("OutboundLink")],1),e._v(")")])])])]),e._v(" "),s("h3",{attrs:{id:"ticket-secrets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ticket-secrets"}},[e._v("#")]),e._v(" Ticket Secrets")]),e._v(" "),s("p",[e._v("For static and dynamic provisioning, you must specify a Secret, which is the base64 representation of the ticket, to enable the POSIX client to communicate with a secure MapR cluster. The ticket for the POSIX client can be generated on the data-fabric cluster using the maprlogin("),s("a",{attrs:{href:"https://docs.datafabric.hpe.com/62/SecurityGuide/ThemaprloginUtility.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://docs.datafabric.hpe.com/62/SecurityGuide/ThemaprloginUtility.html"),s("OutboundLink")],1),e._v(") utility.")]),e._v(" "),s("h3",{attrs:{id:"maprlogin"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#maprlogin"}},[e._v("#")]),e._v(" Maprlogin")]),e._v(" "),s("p",[e._v("Authenticates logins to secure HPE Ezmeral Data Fabric clusters.\nThe /opt/mapr/bin/maprlogin command line tool enables users to log into secure MapR clusters. Users authenticate themselves to the cluster with a maprticket("),s("a",{attrs:{href:"https://docs.datafabric.hpe.com/62/SecurityGuide/GeneratingMapRUserTicket.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://docs.datafabric.hpe.com/62/SecurityGuide/GeneratingMapRUserTicket.html"),s("OutboundLink")],1),e._v(") that can be generated in the following ways:")]),e._v(" "),s("ul",[s("li",[e._v("Run maprlogin password to authenticate with username and password.")])]),e._v(" "),s("p",[e._v("This command prompts for the user password, then generates a HPE Ezmeral Data Fabric user ticket associated with the UNIX user ID. By default, tickets on Linux systems are generated in the /tmp directory and are named in the form maprticket_UID.")]),e._v(" "),s("p",[e._v("Example:")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" edf@qa-node113:~/SecurityInstall"),s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# maprlogin password")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("Password "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" user "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'edf'")]),e._v(" at cluster "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'cluster1'")]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v("\nMapR credentials of user "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'edf'")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" cluster "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'cluster1'")]),e._v(" are written to "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v("'/tmp/maprticket_0'")]),e._v("\nedf@qa-node113:~/SecurityInstall"),s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("#")]),e._v("\n")])])]),s("p",[e._v("Converting a String to Base64\nThe following command shows how to convert a MapR ticket to base64 representation:")]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("echo")]),e._v(" -n "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"cluster-name <base64-encoded ticket-value>"')]),e._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" base64 \n")])])]),s("p",[e._v("The following example shows a ticket Secret:")]),e._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("apiVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" v1\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("kind")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Secret\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("metadata")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" mapr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("ticket"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secret\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" mapr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("examples\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Opaque\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("data")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("CONTAINER_TICKET")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" CHANGETHIS"),s("span",{pre:!0,attrs:{class:"token tag"}},[e._v("!")]),e._v("\n")])])]),s("h3",{attrs:{id:"example"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#example"}},[e._v("#")]),e._v(" Example:")]),e._v(" "),s("p",[e._v("Mounting a PersistentVolume for Dynamic Provisioning Using Container Storage Interface (CSI) Storage Plugin")]),e._v(" "),s("h3",{attrs:{id:"about-this-task"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#about-this-task"}},[e._v("#")]),e._v(" About this task")]),e._v(" "),s("p",[e._v("This example also uses a PersistentVolume. when you use the dynamic provisioner, you do not need to create a PersistentVolume manually. The PersistentVolume is created automatically based on the parameters specified in the referenced StorageClass.\nThe following example uses a PersistentVolumeClaim that references a Storage Class. In this example, a Kubernetes administrator has created a storage class called test-secure-sc for pod creators to use when they want to create persistent storage for their pods. In this example, it is important for the created pod storage to survive the deletion of a pod.\nThe information on this page is valid for both FUSE POSIX and Loopback NFS plugins. Examples or tables that mention the FUSE POSIX provisioner (com.mapr.csi-kdf) are equally valid for the Loopback NFS provisioner (com.mapr.csi-nfskdf).")]),e._v(" "),s("ol",[s("li",[e._v("Create a StorageClass similar to the following:")])]),e._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("apiVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" storage.k8s.io/v1\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("kind")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" StorageClass\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("metadata")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("secure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("sc\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("namespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("csi\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("provisioner")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" com.mapr.csi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("kdf\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("allowVolumeExpansion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token boolean important"}},[e._v("true")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("reclaimPolicy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Delete\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("parameters")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csiProvisionerSecretName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"mapr-provisioner-secrets"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csiProvisionerSecretNamespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"test-csi"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csiNodePublishSecretName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"mapr-ticket-secret"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("csiNodePublishSecretNamespace")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"test-csi"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("restServers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"10.10.10.210:8443"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("cldbHosts")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"10.10.10.210:7222"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("cluster")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"clusterA"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("securityType")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"secure"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("namePrefix")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"csi-pv"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("mountPrefix")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"/csi"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("advisoryquota")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"100M"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("trackMemory")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"false"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("logLevel")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"error"')]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("retainLogs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"false"')]),e._v("\n")])])]),s("ol",{attrs:{start:"2"}},[s("li",[e._v("Deploy the .yaml file on the pod by running the following command:")])]),e._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" oc apply -f "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v("filename"),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(".yaml\n")])])]),s("h3",{attrs:{id:"validating-edf-with-deploying-wordpress-application"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#validating-edf-with-deploying-wordpress-application"}},[e._v("#")]),e._v(" Validating EDF with deploying WordPress application")]),e._v(" "),s("p",[e._v("This section covers the steps to validate the Ezmeral Data Fabric deployment (EDF) by deploying 2-tier application along with MySQL database.\nDeploying WordPress application")]),e._v(" "),s("p",[e._v("Refer to the section "),s("a",{attrs:{href:"#validating-odf-with-deploying-wordpress-application"}},[e._v("Validating ODF with deploying WordPress application")]),e._v(" for deploying WordPress application.")])])}),[],!1,null,null,null);t.default=r.exports}}]);