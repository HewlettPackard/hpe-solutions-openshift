(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{551:function(e,t,n){"use strict";n.r(t);var a=n(42),s=Object(a.a)({},(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h1",{attrs:{id:"virtual-node-configuration"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#virtual-node-configuration"}},[e._v("#")]),e._v(" Virtual node configuration")]),e._v(" "),n("p",[e._v("This section describes the process to deploy virtualization hosts for\nOpenShift. This section outlines the steps required to configure virtual\nmachine master and worker nodes. At a high level, these steps are as\nfollows:")]),e._v(" "),n("ul",[n("li",[n("p",[e._v("Deploying the vSphere hosts")])]),e._v(" "),n("li",[n("p",[e._v("Creating the data center, cluster, and adding hosts into the cluster")])]),e._v(" "),n("li",[n("p",[e._v("Creating a datastore in vCenter")])]),e._v(" "),n("li",[n("p",[e._v("Create virtual master nodes")])]),e._v(" "),n("li",[n("p",[e._v("Deploying virtual worker nodes")])])]),e._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),n("p",[e._v("Hewlett Packard Enterprise utilized a consistent method for deployment\nthat would allow for mixed deployments of virtual and physical master\nand worker nodes and built this solution on bare metal using the Red Hat\nOpenShift Container Platform user-provisioned infrastructure. For more\ndetails on the bare metal provisioner, refer to\n"),n("a",{attrs:{href:"https://cloud.redhat.com/openshift/install/metal/user-provisioned",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://cloud.redhat.com/openshift/install/metal/user-provisioned"),n("OutboundLink")],1),e._v(". If\nthe intent is to have an overall virtual environment, it is recommended\nthe installation user utilizes Red Hat's virtual provisioning methods\nfound at\n"),n("a",{attrs:{href:"https://docs.openshift.com/container-platform/4.5/installing/installing_vsphere/installing-vsphere.html#installing-vsphere",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://docs.openshift.com/container-platform/4.6/installing/installing_vsphere/installing-vsphere.html#installing-vsphere"),n("OutboundLink")],1),e._v(".")])]),e._v(" "),n("h2",{attrs:{id:"deploying-vsphere-hosts"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#deploying-vsphere-hosts"}},[e._v("#")]),e._v(" Deploying vSphere hosts")]),e._v(" "),n("p",[e._v("Refer to the section "),n("a",{attrs:{href:"./Server-Profiles#server-profiles"}},[e._v("Server\nProfiles")]),e._v("\nin this document to create the server profile for the vSphere hosts.")]),e._v(" "),n("p",[e._v("After the successful creation of the server profile, install the\nhypervisor. The following steps describes the process to install the\nhypervisor:")]),e._v(" "),n("ol",[n("li",[n("p",[e._v("From the HPE OneView interface, navigate to Server Profiles and\nselect ESXi-empty-volume Server Profile, Select "),n("strong",[e._v("Actions > Launch\nConsole.")])])]),e._v(" "),n("li",[n("p",[e._v("From the Remote Console window, choose "),n("strong",[e._v("Virtual Drives -> Image\nFile CD-ROM/DVD")]),e._v(" from the "),n("strong",[e._v("iLO options")]),e._v(" menu bar.")])]),e._v(" "),n("li",[n("p",[e._v("Navigate to the VMware ESXi 6.7 ISO file located on the installation\nsystem. Select the ISO file and click "),n("strong",[e._v("Open")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("If the server is in the powered off state, power switch on the\nserver by selecting "),n("strong",[e._v("Power Switch -> Momentary Press.")])])]),e._v(" "),n("li",[n("p",[e._v("During boot, press "),n("strong",[e._v("F11")]),e._v(" Boot Menu and select iLO Virtual USB 3:\niLO Virtual CD-ROM.")])]),e._v(" "),n("li",[n("p",[e._v("When the VMware ESXi installation media has finished loading,\nproceed through the VMware user prompts. For storage device, select\nthe 40GiB OS volume created on the HPE Image Streamer during server\nprofile creation and "),n("strong",[e._v("set the root password.")])])]),e._v(" "),n("li",[n("p",[e._v("Wait until the vSphere installation is complete.")])]),e._v(" "),n("li",[n("p",[e._v("After the installation is complete, press "),n("strong",[e._v("F2")]),e._v(" to enter the\nvSphere host configuration page and update the IP address, gateway,\nDNS, hostname of the host and enable SSH.")])]),e._v(" "),n("li",[n("p",[e._v("After the host is reachable, proceed with the next section.")])])]),e._v(" "),n("h3",{attrs:{id:"hpe-oneview-for-vmware-vcenter"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#hpe-oneview-for-vmware-vcenter"}},[e._v("#")]),e._v(" HPE OneView for VMware vCenter")]),e._v(" "),n("p",[e._v("HPE OneView for VMware vCenter is a single, integrated plug-in\napplication for VMware vCenter management. This enables the vSphere\nadministrator to quickly obtain context-aware information about HPE\nServers and HPE Storage in their VMware vSphere data center directly\nfrom within vCenter. This application enables the vSphere administrator\nto easily manage physical servers and storage, datastores, and virtual\nmachines. By providing the ability to clearly view and directly manage\nthe HPE Infrastructure from within the vCenter console, the productivity\nof VMware administrator increases. This also enhances the ability to\nensure quality of service.")]),e._v(" "),n("p",[e._v("For more details, refer to the HPE documentation at\n"),n("a",{attrs:{href:"https://h20392.www2.hpe.com/portal/swdepot/displayProductInfo.do?productNumber=HPVPR",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://h20392.www2.hpe.com/portal/swdepot/displayProductInfo.do?productNumber=HPVPR"),n("OutboundLink")],1),e._v(".")]),e._v(" "),n("h3",{attrs:{id:"creating-the-data-center-cluster-and-adding-hosts-in-vmware-vcenter"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#creating-the-data-center-cluster-and-adding-hosts-in-vmware-vcenter"}},[e._v("#")]),e._v(" Creating the Data center, Cluster and adding Hosts in VMware vCenter")]),e._v(" "),n("p",[e._v("This section assumes a VMware vCenter server is available within the\ninstallation environment. A data center is a structure in VMware vCenter\nwhich contains clusters, hosts, and datastore. To begin with, a data\ncenter needs to be created, followed by the clusters and adding hosts\ninto the clusters.")]),e._v(" "),n("p",[e._v("To create a data center, a cluster enabled with vSAN and DRS and adding\nhosts, the installation user will need to edit the vault file and the\nvariables YAML file. Using an editor, open the file\n/opt/hpe/solutions/ocp/"),n("em",[e._v("hpe-solutions-openshift/synergy/scalable/vsphere/vcenter/roles/prepare_vcenter/vars/main.yml")]),e._v("\nto provide the names for data center, clusters and vSphere hostnames. A\nsample input file is listed and as follows. Installation user should\nmodify this file to suit the environment.")]),e._v(" "),n("p",[e._v("In the Ansible vault file ("),n("em",[e._v("secret.yml")]),e._v(") found at\n/opt/hpe/solutions/ocp/"),n("em",[e._v("hpe-solutions-openshift/synergy/scalable/vsphere/vcenter")]),e._v(",\nprovide the vCenter and the vSphere host credentials.")]),e._v(" "),n("div",{staticClass:"language-yaml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-yaml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# vsphere hosts credentials")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vsphere_username")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <username"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vsphere_password")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <password"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# vcenter hostname/ip address and credentials")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vcenter_hostname")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" x.x.x.x\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vcenter_username")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <username"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vcenter_password")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <password"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n")])])]),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),n("p",[e._v("This section assumes all the virtualization hosts have a common username\nand password. If it does not have a common username and password, it is\nup to the installation user to add the virtualization hosts within the\nappropriate cluster.")])]),e._v(" "),n("p",[e._v("Variables for running the playbook can be found at\n/opt/hpe/solutions/ocp/"),n("em",[e._v("hpe-solutions-openshift/synergy/scalable/vsphere/vcenter/roles/prepare_vcenter/vars/main.yml")]),e._v(".")]),e._v(" "),n("div",{staticClass:"language-yaml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-yaml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# custom name for data center to be created.")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("datacenter_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" datacenter\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# custom name of the compute clusters with the ESXi hosts for Management VMs.")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("management_cluster_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" management"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("-")]),e._v("cluster\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# hostname or IP address of the vsphere hosts utilized for the management nodes.")]),e._v("\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vsphere_host_01")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" 10.0.x.x\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vsphere_host_02")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" 10.0.x.x\n\n"),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("vsphere_host_03")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" 10.0.x.x\n")])])]),n("p",[e._v("After the variable files are updated with the appropriate values,\nexecute the following command within the installer VM to create the data\ncenter, clusters, and add hosts into respective clusters.")]),e._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("cd")]),e._v(" /opt/hpe/solutions/ocp/hpe-solutions-openshift/synergy/scalable/vsphere/vcenter/\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" ansible-playbook playbooks/prepare_vcenter.yml –ask-vault-pass\n")])])]),n("h3",{attrs:{id:"creating-a-datastore-in-vcenter"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#creating-a-datastore-in-vcenter"}},[e._v("#")]),e._v(" Creating a Datastore in vCenter")]),e._v(" "),n("p",[e._v("A datastore needs to be created in VMware vCenter from the volume carved\nout of HPE Storage SANs to store the VMs. The following are the steps to\ncreate a datastore in vCenter:")]),e._v(" "),n("ol",[n("li",[n("p",[e._v("From the vSphere Web Client navigator, right-click the cluster,\nselect "),n("strong",[e._v("Storage")]),e._v(" from the menu, and then select the "),n("strong",[e._v("New\nDatastore")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("From the Type page, select "),n("strong",[e._v("VMFS")]),e._v(" as the Datastore type and click\n"),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Enter the datastore name and if necessary, select the placement\nlocation for the datastore and click "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Select the device to use for the datastore and click "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("From VMFS version page, select "),n("strong",[e._v("VMFS 6")]),e._v(" and click "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Define the following configuration requirements for the datastore as\nper the installation environment and click "),n("strong",[e._v("Next")]),e._v(".")]),e._v(" "),n("p",[e._v("a.  Specify partition configuration")]),e._v(" "),n("p",[e._v("b.  Datastore Size")]),e._v(" "),n("p",[e._v("c.  Block Size")]),e._v(" "),n("p",[e._v("d.  Space Reclamation Granularity")]),e._v(" "),n("p",[e._v("e.  Space Reclamation Priority")])]),e._v(" "),n("li",[n("p",[e._v("On the Ready to complete page, review the Datastore configuration\nand click "),n("strong",[e._v("Finish")]),e._v(".")])])]),e._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),n("p",[e._v("If you utilize virtual worker nodes, repeat this section to create a\nDatastore to store the worker virtual machines.")])]),e._v(" "),n("h3",{attrs:{id:"red-hat-openshift-container-platform-sizing"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#red-hat-openshift-container-platform-sizing"}},[e._v("#")]),e._v(" Red Hat OpenShift Container Platform sizing")]),e._v(" "),n("p",[e._v("Red Hat OpenShift Container Platform sizing varies depending on the\nrequirements of the organization and type of deployment. This section\nhighlights the host sizing details recommended by Red Hat.")]),e._v(" "),n("table",[n("thead",[n("tr",[n("th",[e._v("Resource")]),e._v(" "),n("th",[e._v("Bootstrap node")]),e._v(" "),n("th",[e._v("Master node")]),e._v(" "),n("th",[e._v("Worker node")])])]),e._v(" "),n("tbody",[n("tr",[n("td",[e._v("CPU")]),e._v(" "),n("td",[e._v("4")]),e._v(" "),n("td",[e._v("4")]),e._v(" "),n("td",[e._v("4")])]),e._v(" "),n("tr",[n("td",[e._v("Memory")]),e._v(" "),n("td",[e._v("16GB")]),e._v(" "),n("td",[e._v("16GB")]),e._v(" "),n("td",[e._v("16GB")])]),e._v(" "),n("tr",[n("td",[e._v("Disk storage")]),e._v(" "),n("td",[e._v("120GB")]),e._v(" "),n("td",[e._v("120GB")]),e._v(" "),n("td",[e._v("120GB")])]),e._v(" "),n("tr",[n("td",[e._v("Disk storage")]),e._v(" "),n("td",[e._v("120GB")]),e._v(" "),n("td",[e._v("120GB")]),e._v(" "),n("td",[e._v("120GB")])])])]),e._v(" "),n("p",[e._v("Disk partitions on each of the nodes are as follows.")]),e._v(" "),n("ul",[n("li",[n("p",[e._v("/var -- 40GB")])]),e._v(" "),n("li",[n("p",[e._v("/usr/local/bin -- 1GB")])]),e._v(" "),n("li",[n("p",[e._v("Temporary directory -- 1GB")])])]),e._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),n("p",[e._v("Sizing for worker nodes is ultimately dependent on the container\nworkloads and their CPU, memory, and disk requirements.")]),e._v(" "),n("p",[e._v("For more information about Red Hat OpenShift Container Platform sizing,\nrefer to the Red Hat OpenShift Container Platform 4.6 product\ndocumentation at\n"),n("a",{attrs:{href:"https://access.redhat.com/documentation/en-us/openshift_container_platform/4.5/html/scalability_and_performance/index",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html/scalability_and_performance/index"),n("OutboundLink")],1),e._v(".")])]),e._v(" "),n("h3",{attrs:{id:"deploying-virtual-master-nodes"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#deploying-virtual-master-nodes"}},[e._v("#")]),e._v(" Deploying virtual master nodes")]),e._v(" "),n("p",[e._v("This section outlines the steps to create the virtual machines used as\nthe master nodes.")]),e._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[e._v("NOTE")]),e._v(" "),n("p",[e._v("This section utilized vSphere rules such as affinity and anti-affinity\nrules to ensure no two master nodes are present on the same vSphere\nhost, hence it is essential to enable vMotion in all the vSphere hosts.\nIf not enabled, select the vSphere host in the VMware vCenter server\nuser interface, "),n("strong",[e._v("click -> Configure -> Networking -> VMkernel\nadapters -> Management Network -> Edit")]),e._v(" and select the checkbox\nagainst vMotion to enable vMotion.")])]),e._v(" "),n("p",[e._v("To create the virtual machines for the OpenShift master nodes, edit the\nvariables file. Use an editor such as Vim or Nano, open the file\n/opt/hpe/solutions/ocp/"),n("em",[e._v("hpe-solutions-openshift/synergy/scalable/vsphere/virtual_nodes\n/roles/deploy_vm/vars/main.yml.")]),e._v(" The variable file contains information\nabout the VMs, vCenter, hostnames, IP addresses, memory, and CPU. A\nsample variable file is provided and as follows. The installation user\nshould modify the file to make it suitable for the target environment.")]),e._v(" "),n("div",{staticClass:"language-yaml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-yaml"}},[n("code",[e._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Name of the Data center")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("datacenter_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <datacentername"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Name of the compute clusters with the ESXi hosts for Management VMs")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("management_cluster_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <data_cluster_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Name of the Datastore to store the VMs")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("management_datastore_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <datastore_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Name of the coreOS guest image")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("guest_template")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" coreos64Guest\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Disk size in GB/GiB")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("bootstrap_disk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("120")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("master_disk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("120")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("lb_disk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("50")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# number of CPUs")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("bootstrap_cpu")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("4")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("master_cpu")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("4")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("lb_cpu")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("4")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Memory size in MB/MiB")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("bootstrap_memory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("16400")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("master_memory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("16400")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("lb_memory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[e._v("16400")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("gateway")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <replace_with_gateway_ip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("dns_server")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <replace_with_dns_server_ip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("domain")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <replace_with_domain_ip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# name of the master, bootstrap and lb nodes < short names, not the FQDN >")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("bootstrap01_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <bootstrap01_host_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("master01_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <master01_host_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("master02_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <master02_host_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("master03_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <master03_host_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("lb01_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" <lb01_host_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(">")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("domain_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<sub_domain>"')]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# Network names for the management network")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("datacenter_network_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[e._v('"<network_name>"')]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# vSphere affinity & anti-affinity rules")]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("affinity_rule_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[e._v('"vsphere-anti-affinty-rule"')]),e._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token key atrule"}},[e._v("anti_affinity_rule_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[e._v('"vsphere-affinty-rule"')]),e._v("\n")])])]),n("p",[e._v("After the variable file is updated, execute the following command from\nthe installer machine to deploy the specified VMs.")]),e._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v("cd")]),e._v(" /opt/hpe/solutions/ocp/hpe-solutions-openshift/synergy/scalable/vsphere/virtual_nodes\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" ansible-playbook playbooks/deploy_vm.yml –ask-vault-pass\n")])])]),n("p",[n("em",[e._v("deploy_vm.yml")]),e._v(" playbooks create 3x VMs to be used as master nodes, 1x\nVM to be used as load balancer node and 1x VM to be used as a bootstrap\nnode. All the master VMs will be deployed on different hosts whereas\nbootstrap & haproxy VMs will be deployed on any single host.")]),e._v(" "),n("p",[e._v("Wait for some time for vSphere rules to be applicable on VMs. vSphere\nrules can be viewed at "),n("strong",[e._v("vCenter server -> Datacenter -> Cluster ->\nConfigure -> VM/Host Rules")]),e._v(".The 3 master nodes are part of the\n"),n("em",[e._v("vsphere-anti-affinity-rule")]),e._v(" and each master VM will reside on a\ndifferent vSphere host. The bootstrap and load balancer VMs are part of\nthe "),n("em",[e._v("vsphere-affinity-rule")]),e._v(" and they are co-resident on one of 3 vSphere\nhosts.")]),e._v(" "),n("p",[e._v("It is recommended to ensure the "),n("em",[e._v("Boot Delay")]),e._v(" is long enough to enable OS\ninstallation via PXE server.")]),e._v(" "),n("p",[e._v("After the virtual machines are successfully created, refer to the\nfollowing steps to install the operating system on the bootstrap node\nand the master nodes:")]),e._v(" "),n("ol",[n("li",[n("p",[e._v("Ensure that the location of ignition files of the corresponding\nnodes is updated in the PXE configuration files.")])]),e._v(" "),n("li",[n("p",[e._v("Ensure the MAC address of the network adapter in VM is updated with\nthe corresponding IP address in the DHCP configuration file.")])]),e._v(" "),n("li",[n("p",[e._v("Ensure that the load balancer server is up and running.")])]),e._v(" "),n("li",[n("p",[e._v("From the VMware vCenter Server, select the VM, and launch the VM\nRemote console.")])]),e._v(" "),n("li",[n("p",[e._v("From the Remote Console window, power on the VM.")])]),e._v(" "),n("li",[n("p",[e._v("While booting, select the appropriate OS label.")])]),e._v(" "),n("li",[n("p",[e._v("Wait until the OS installation is complete.")])]),e._v(" "),n("li",[n("p",[e._v("Verify the installation by logging on to the node from the installer\nVM using the following command.")])])]),e._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[e._v("ssh")]),e._v(" core@"),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v(" replace_with_node_fqdn_or_ip "),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n")])])]),n("p",[e._v("After the RHCOS master nodes are ready, refer to the section "),n("RouterLink",{attrs:{to:"/Solution-Deployment/OCP-Cluster-deployment.html#red-hat-openshift-container-platform-cluster-deployment"}},[e._v("Red Hat\nOpenShift Container Platform\ndeployment")]),e._v("\nin this document to create the OpenShift 4 cluster.")],1),e._v(" "),n("h2",{attrs:{id:"deploying-virtual-worker-nodes"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#deploying-virtual-worker-nodes"}},[e._v("#")]),e._v(" Deploying virtual worker nodes")]),e._v(" "),n("p",[e._v("This section outlines the steps to create virtual machines and configure\nthem to be used as worker nodes.")]),e._v(" "),n("h3",{attrs:{id:"creating-virtual-machines"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#creating-virtual-machines"}},[e._v("#")]),e._v(" Creating virtual machines")]),e._v(" "),n("p",[e._v("This section outlines the steps to create virtual machines.")]),e._v(" "),n("ol",{attrs:{start:"4"}},[n("li",[n("p",[e._v("Login to vCenter using the Web Client and select an ESXi Host.\nRight-click the host and then click "),n("strong",[e._v("New Virtual Machine")]),e._v(" to open\na "),n("em",[e._v("New Virtual Machine Wizard")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("From "),n("em",[e._v("Select a creation type")]),e._v(", select "),n("strong",[e._v("Create a new virtual\nmachine")]),e._v(" and click "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Enter a unique "),n("em",[e._v("Name")]),e._v(" for the VM and select the "),n("strong",[e._v("Datacenter")]),e._v(".\nClick "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Select the "),n("strong",[e._v("Cluster")]),e._v(" on which the VM can be deployed. Click\n"),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Select the "),n("strong",[e._v("Datastore")]),e._v(" on which the VM can be stored and click\n"),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("On the Select compatibility page, choose "),n("strong",[e._v("ESXI 6.7 and later")]),e._v(" and\nclick "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("On the Select a guest OS page, choose the Guest OS family as\n"),n("strong",[e._v("Linux")]),e._v(" and Guest OS Version as "),n("strong",[e._v("Red Hat Enterprise Linux 7 (64\nbit)")]),e._v(" (in case of RHEL worker) and "),n("strong",[e._v("Red Hat CoreOS")]),e._v(" (in case of\nRed Hat CoreOS worker) and select "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("In the Customize hardware page, configure the Virtual Hardware with\n"),n("strong",[e._v("4 CPU")]),e._v(", "),n("strong",[e._v("16 GB")]),e._v(" Memory, "),n("strong",[e._v("150 GB")]),e._v(" "),n("strong",[e._v("dual Hard Disk")]),e._v(" as per\nrequirement and attach the Operating System from the datastore.\nSelect the Connect at "),n("strong",[e._v("Power on")]),e._v(" option and click "),n("strong",[e._v("Next")]),e._v(".")])]),e._v(" "),n("li",[n("p",[e._v("Review the virtual machine configuration before deploying the\nvirtual machine and click "),n("strong",[e._v("Finish")]),e._v(" to complete the New Virtual\nMachine wizard.")])])]),e._v(" "),n("h3",{attrs:{id:"red-hat-coreos-worker-nodes"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#red-hat-coreos-worker-nodes"}},[e._v("#")]),e._v(" Red Hat CoreOS worker nodes")]),e._v(" "),n("p",[e._v("Refer to the section "),n("RouterLink",{attrs:{to:"/Additional-Features-and-Functionality/Openshift-Virtualization.html#creating-virtual-machines"}},[e._v("Creating virtual\nmachines")]),e._v("\nin the document to create virtual machines. After the virtual machines\nare successfully created, refer to the following steps to install the\noperating system on the worker nodes:")],1),e._v(" "),n("ol",{attrs:{start:"13"}},[n("li",[n("p",[e._v("Ensure that the location of ignition files of the corresponding\nnodes is updated in the PXE configuration files.")])]),e._v(" "),n("li",[n("p",[e._v("Ensure the MAC address of the network adapter in VM is updated with\nthe corresponding IP address in the DHCP configuration file.")])]),e._v(" "),n("li",[n("p",[e._v("Ensure that the load balancer server is up and running.")])]),e._v(" "),n("li",[n("p",[e._v("From the VMware vCenter Server, select the VM and launch the VM\nRemote console.")])]),e._v(" "),n("li",[n("p",[e._v("From the Remote Console window, power on the VM.")])]),e._v(" "),n("li",[n("p",[e._v("While booting, select the appropriate OS label.")])]),e._v(" "),n("li",[n("p",[e._v("Wait until the OS installation is complete.")])]),e._v(" "),n("li",[n("p",[e._v("Verify the installation by logging on to the node from the installer\nVM using the following command.")])])]),e._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[e._v("ssh")]),e._v(" core@"),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v(" replace_with_node_fqdn_or_ip "),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n")])])]),n("p",[e._v("After the RHCOS worker nodes are up and running, refer to the section\n"),n("RouterLink",{attrs:{to:"/Solution-Deployment/OCP-worker-nodes.html#adding-rhel-7-6-worker-nodes"}},[e._v("Adding Red Hat CoreOS worker\nnodes")]),e._v("\nin the document to add them to OpenShift 4 cluster.")],1),e._v(" "),n("h3",{attrs:{id:"rhel-7-6-worker-nodes"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rhel-7-6-worker-nodes"}},[e._v("#")]),e._v(" RHEL 7.6 worker nodes")]),e._v(" "),n("p",[e._v("Refer to the section "),n("RouterLink",{attrs:{to:"/Additional-Features-and-Functionality/Openshift-Virtualization.html#creating-virtual-machines"}},[e._v("Creating virtual\nmachines")]),e._v("\nin this document to create virtual machines. After the virtual machines\nare successfully created, follow these steps to install the operating\nsystem on the worker nodes:")],1),e._v(" "),n("ol",{attrs:{start:"21"}},[n("li",[n("p",[e._v("Ensure that the location of ignition files of the corresponding\nnodes is updated in the PXE configuration files.")])]),e._v(" "),n("li",[n("p",[e._v("Ensure the MAC address of the network adapter in VM is updated with\nthe corresponding IP address in the DHCP configuration file.")])]),e._v(" "),n("li",[n("p",[e._v("Ensure that the load balancer server is up and running.")])]),e._v(" "),n("li",[n("p",[e._v("From the VMware vCenter Server, select the VM, and launch the VM\nRemote console.")])]),e._v(" "),n("li",[n("p",[e._v("From the Remote Console window, power on the VM.")])]),e._v(" "),n("li",[n("p",[e._v("While booting, select the appropriate OS label.")])]),e._v(" "),n("li",[n("p",[e._v("Wait until the OS installation is complete.")])]),e._v(" "),n("li",[n("p",[e._v("Verify the installation by logging on to the node from the installer\nVM using the following command.")])])]),e._v(" "),n("div",{staticClass:"language-bash extra-class"},[n("pre",{pre:!0,attrs:{class:"language-bash"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[e._v("ssh")]),e._v(" root@"),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),e._v(" node_fqdn or node_ip_address"),n("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v("\n")])])]),n("p",[e._v("Once the RHEL 7.6 nodes are reachable, refer to the section "),n("RouterLink",{attrs:{to:"/Solution-Deployment/Physical-node-configuration.html#red-hat-openshift-worker-nodes-with-rhel"}},[e._v("Preparing\nworker nodes with\nRHEL")]),e._v("\nin the document to prepare the RHEL worker nodes. After preparing the\nworker nodes, refer to the section "),n("RouterLink",{attrs:{to:"/Solution-Deployment/OCP-worker-nodes.html#adding-rhel-7-6-worker-nodes"}},[e._v("Adding RHEL 7.6 worker\nnodes")]),e._v("\nin the document to add them to the OpenShift 4 cluster.")],1)])}),[],!1,null,null,null);t.default=s.exports}}]);