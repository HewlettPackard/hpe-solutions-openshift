<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>OCP Cluster Deployment | OpenShift Container Platform 4.10 on HPE DL365 Gen10 Plus Servers</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="Hewlett Packard Enterprise">
    
    <link rel="preload" href="/hpe-solutions-openshift/4.10-dl/assets/css/0.styles.379df3e1.css" as="style"><link rel="preload" href="/hpe-solutions-openshift/4.10-dl/assets/js/app.d2994e5a.js" as="script"><link rel="preload" href="/hpe-solutions-openshift/4.10-dl/assets/js/2.7c26c33b.js" as="script"><link rel="preload" href="/hpe-solutions-openshift/4.10-dl/assets/js/16.d786a800.js" as="script"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/10.48334563.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/11.0f6dbf5f.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/12.35ff5ce7.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/13.20e31dc2.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/14.0e9a44bf.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/15.380107f7.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/17.15c44ee1.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/18.0a61828a.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/19.44696c60.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/20.38456837.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/21.6ef7e0da.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/22.735e9f37.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/23.d0cfcce9.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/24.e4cc79dc.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/25.8d86fdbd.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/26.4341c805.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/3.f5d7d4b1.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/4.37a7e22b.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/5.e7dabacf.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/6.67c17003.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/7.268c772b.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/8.0063cc8c.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-dl/assets/js/9.251f34c2.js">
    <link rel="stylesheet" href="/hpe-solutions-openshift/4.10-dl/assets/css/0.styles.379df3e1.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/hpe-solutions-openshift/4.10-dl/" class="home-link router-link-active"><!----> <span class="site-name">OpenShift Container Platform 4.10 on HPE DL365 Gen10 Plus Servers</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/hpe-solutions-openshift/4.10-dl/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="http://www.hpe.com/info/ra" target="_blank" rel="noopener noreferrer" class="nav-link external">
  RA Library
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/hpe-solutions-openshift/4.10-dl/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="http://www.hpe.com/info/ra" target="_blank" rel="noopener noreferrer" class="nav-link external">
  RA Library
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Red Hat OpenShift Container Platform 4.10 on DL Servers</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Solution Overview</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Solution Components</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Solution Deployment</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Additional Features and Functionality</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Troubleshooing by Using Manual Processes</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hpe-solutions-openshift/4.10-dl/Troubleshooting-Using-Manual-Processes/Preparing-execution-environment.html" class="sidebar-link">Preparing the execution environment for RHOCP worker3 node</a></li><li><a href="/hpe-solutions-openshift/4.10-dl/Troubleshooting-Using-Manual-Processes/Deploying-OS-on-Head-Nodes.html" class="sidebar-link">Deploying RHEL 8.5 OS on the head nodes</a></li><li><a href="/hpe-solutions-openshift/4.10-dl/Troubleshooting-Using-Manual-Processes/Installing-and-Configuring-Bind-DNS.html" class="sidebar-link">Installing and configuring master/slave Bind DNS on head nodes</a></li><li><a href="/hpe-solutions-openshift/4.10-dl/Troubleshooting-Using-Manual-Processes/Configuring-Squid-Proxy.html" class="sidebar-link">Deploying Squid proxy on head nodes</a></li><li><a href="/hpe-solutions-openshift/4.10-dl/Troubleshooting-Using-Manual-Processes/OCP-Cluster-Deployment.html" aria-current="page" class="active sidebar-link">OCP Cluster Deployment</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Resosurces and Additional Links</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="ocp-cluster-deployment"><a href="#ocp-cluster-deployment" class="header-anchor">#</a> OCP Cluster Deployment</h1> <p><strong>Generating Kubernetes manifests and ignition files</strong></p> <p>The manifests and ignition files define the master node and worker node configuration and are key components of the RHOCP 4 installation.</p> <p>Prerequisites:</p> <p>Before creating the manifest files and ignition files, it is necessary to download the RHOCP 4 packages.</p> <ul><li>Download the required packages on the installer VM with the following playbook:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># ansible-playbook -i hosts playbooks/download_ocp_package.yml </span>
</code></pre></div><p>To generate Kubernetes manifests and ignition files:</p> <ol><li>Generate Kubernetes manifest file with the following playbook.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># ansible-playbook -i hosts playbooks/generate_manifest.yml </span>
</code></pre></div><ol start="2"><li>Find the ignition files in the following path:</li></ol> <p>/opt/ hpe-solutions-openshift/DL-LTI-Openshift/playbooks/roles/generate_ignition_files/ignitions/</p> <ol start="3"><li>When the ignition files are generated, export the kubeconfig file with the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># export KUBECONFIG= /opt/ hpe-solutions-openshift/DL-LTI-Openshift/playbooks/roles/generate_ignition_files/ignitions/auth/kubeconfig </span>
</code></pre></div><p><strong>Installing and configuring iPXE server</strong></p> <p>To install and configure an iPXE server:</p> <ol><li>Browse to the following directory on the Ansible engine.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># cd /opt/ hpe-solutions-openshift/DL-LTI-Openshift/ </span>
</code></pre></div><ol start="2"><li>Enter the values as per your setup in input.yaml file.</li> <li>Execute the following playbook:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># ansible-playbook -i hosts playbooks/deploy_ipxe_ocp.yml </span>
</code></pre></div><p><strong>Creating bootstrap and master VM on KVM nodes</strong></p> <p>To create bootstrap and RHOCP master VMs on your RHEL 8 Kernel-based Virtual Machine (KVM) host:</p> <ul><li>Run the following virt-install command:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># virt-install -n boot --description &quot;boot&quot; --ram=16384 --vcpu=10 --os-type=Linux --os-variant=rhel8.0 --noreboot --disk pool=home,bus=virtio,size=100 --serial pty --console pty --pxe --network bridge=bridge0,mac=&lt;mac address&gt; </span>
</code></pre></div><p>Waiting for the bootstrap process to complete</p> <p>The bootstrap process for RHOCP begins after the cluster nodes first boot into the persistent RHCOS environment that has been installed to disk. The configuration information provided through the ignition config files is used to initialize the bootstrap process and install RHOCP on the machines. You must wait for the bootstrap process to complete.</p> <ol><li>Login to the installer VM as root user.</li> <li>Execute the following command to bootstrap the nodes:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># openshift-install wait-for bootstrap-complete --log-level=debug </span>
</code></pre></div><p>The following output is displayed:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>DEBUG OpenShift Installer v4.10 

DEBUG Built from commit 425e4ff0037487e32571258640b39f56d5ee5572 

INFO Waiting up to 30m0s <span class="token keyword">for</span> the Kubernetes API at https://api.ocp.pxelocal.local:6443<span class="token punctuation">..</span>. 

INFO API v1.23.3+e419edf up 

INFO Waiting up to 30m0s <span class="token keyword">for</span> bootstrapping to complete<span class="token punctuation">..</span>. 

DEBUG Bootstrap status: complete 

INFO It is now safe to remove the bootstrap resources 
</code></pre></div><p><strong>NOTE</strong></p> <p>Shut down or remove the bootstrap node after step 1 and step 2 are complete.</p> <ol start="3"><li>Provide the PV storage for the registry. Set the image registry storage to an empty directory with the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{&quot;spec&quot;:{&quot;storage&quot;:{&quot;emptyDir&quot;:{}}}}'  </span>
</code></pre></div><ol start="4"><li>Complete the RHOCP 4 cluster installation with the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># openshift-install wait-for install-complete --log-level=debug </span>
</code></pre></div><p>The following output is displayed:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>DEBUG OpenShift Installer v4.10 

DEBUG Built from commit 6ed04f65b0f6a1e11f10afe658465ba8195ac459  

INFO Waiting up to 30m0s <span class="token keyword">for</span> the cluster at https://api.rrocp.pxelocal.local:6443 to initialize<span class="token punctuation">..</span>.  

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">99</span>% complete  

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">99</span>% complete, waiting on authentication, console,image-registry  

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">99</span>% complete  

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">100</span>% complete, waiting on image-registry  

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Cluster operator image-registry is still updating  

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Cluster operator image-registry is still updating  

DEBUG Cluster is initialized  

INFO Waiting up to 10m0s <span class="token keyword">for</span> the openshift-console route to be created<span class="token punctuation">..</span>. 

DEBUG Route found <span class="token keyword">in</span> openshift-console namespace: console  

DEBUG Route found <span class="token keyword">in</span> openshift-console namespace: downloads  

DEBUG OpenShift console route is created  

INFO Install complete<span class="token operator">!</span>  

INFO Access the OpenShift web-console here: https://console-openshift-console.apps.ocp.isv.local 

INFO Login to the console with user: kubeadmin, password: a6hKv-okLUA-Q9p3q-UXLc3 
</code></pre></div><p>The RHOCP cluster is successfully installed.</p> <p><strong>Running Red Hat OpenShift Container Platform Console</strong> 
Prerequisites:</p> <ul><li>The RHOCP cluster installation must be complete.</li></ul> <p><strong>NOTE</strong></p> <p>The installer machine provides the Red Hat OpenShift Container Platform Console link and login details when the RHOCP cluster installation is complete.</p> <p>To access the Red Hat OpenShift Container Platform Console:</p> <ol><li>Open a web browser and enter the following link:</li></ol> <p>https://console-openshift-console.apps.ocp.isv.local</p> <ol start="2"><li>Log in to the Red Hat OpenShift Container Platform Console with the following credentials:</li></ol> <ul><li><strong>Username</strong>: kubeadmin</li> <li><strong>Password:</strong> a6hKv-okLUA-Q9p3q-UXLc3</li></ul> <p><strong>NOTE</strong></p> <p>If the password is lost or forgotten, search for the kubeadmin-password file located in the /opt/ hpe-solutions-openshift/DL-LTI-Openshift/playbooks/roles/generate_ignition_files/ignitions/auth/kubeadmin-password directory on the installer machine.</p> <p>The following figure shows the Red Hat OpenShift Container Platform Console after successful deployment:</p> <p><img src="/hpe-solutions-openshift/4.10-dl/assets/img/f25.32fc445e.png" alt=""></p> <p><strong>FIGURE 25</strong>. Red Hat OpenShift Container Platform Console login screen</p> <p><strong>Adding RHEL 8.5 compute machines to RHOCP cluster</strong></p> <p><strong>Creating RHEL 7.9 installer machine on head nodes</strong></p> <p>To create a RHEL7.9 VM for adding RHEL 8.5 workers to the RHOCP cluster:</p> <ul><li>Run the following command on your RHEL 8 KVM host using the virt-install utility:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># virt-install --name Installer --memory 2048 --vcpus 2 --disk size=80 --os-variant rhel7.0 --cdrom /home/username/Downloads/RHEL7.iso </span>
</code></pre></div><p><strong>Setting up RHEL 7.9 installer machine</strong></p> <p>To set up the installer machine running RHEL 7.9 and run the playbook:</p> <ol><li>Log in to the RHEL7.9 Installer Machine and then register and attach the host pool with Red Hat using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager register </span>
</code></pre></div><ol start="2"><li>Generate a list of available subscriptions using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager list --available --matches '*OpenShift*' </span>
</code></pre></div><ol start="3"><li>Find the pool ID for RHOCP subscription from the output generated in step 2 and add it in the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager attach --pool=&lt;pool_id&gt; </span>
</code></pre></div><ol start="4"><li>Enable the repositories required by RHOCP 4.10 with the following commands:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager repos \ </span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-rpms&quot;</span> <span class="token punctuation">\</span> 

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-extras-rpms&quot;</span> <span class="token punctuation">\</span> 

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-ansible-2.9-rpms&quot;</span> <span class="token punctuation">\</span> 

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-ose-4.10-rpms&quot;</span> 
</code></pre></div><ol start="5"><li>Install the required packages including openshift-ansible.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># yum install openshift-ansible openshift-clients jq </span>
</code></pre></div><p><strong>Setting up RHEL compute node</strong></p> <p>Prerequisites:</p> <ul><li>The RHEL 8.5 OS must be deployed on the compute nodes.</li></ul> <p>To set up a RHEL compute node for each worker node:</p> <ol><li>Log in to the RHEL host and then register and attach the host pool with Red Hat using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager register </span>
</code></pre></div><ol start="2"><li>Generate a list of available subscriptions using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager list --available --matches '*OpenShift*' </span>
</code></pre></div><ol start="3"><li>Find the pool ID for RHOCP subscription from the output generated in step 2 and add it in the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager attach --pool=&lt;pool_id&gt; </span>
</code></pre></div><ol start="4"><li>Enable the repositories required by RHOCP 4.10 with the following commands:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># subscription-manager repos \ </span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-8-for-x86_64-baseos-rpms&quot;</span> <span class="token punctuation">\</span> 

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-8-for-x86_64-appstream-rpms&quot;</span> <span class="token punctuation">\</span> 

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhocp-4.10-for-rhel-8-x86_64-rpms&quot;</span> <span class="token punctuation">\</span> 

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;fast-datapath-for-rhel-8-x86_64-rpms&quot;</span> 
</code></pre></div><ol start="5"><li>Stop and disable firewalld on the host.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># systemctl disable --now firewalld.service </span>
</code></pre></div><p><strong>Adding RHEL compute node to RHOCP cluster using RHEL 7.9 installer machine</strong></p> <p>This section covers the steps to add compute machines that use Red Hat Enterprise Linux 8 as the operating system to an RHOCP 4.10 cluster.</p> <p>Prerequisites:</p> <ul><li>The required packages must be installed, and the necessary configuration must be performed on the RHEL 7.9 installer machine.</li> <li>RHEL hosts must be prepared for installation.</li></ul> <p>To add RHEL 8 worker nodes manually to an existing cluster using RHEL 7.9 installer VM machine:</p> <ol><li>Create an Ansible inventory file in the path/inventory/hosts directory. This inventory file defines your compute machine hosts and the required variables:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token punctuation">[</span>all:vars<span class="token punctuation">]</span> 

<span class="token comment"># Specify the username that runs the Ansible tasks on the remote compute machines. </span>

<span class="token comment"># ansible_user=root </span>

<span class="token comment"># If you do not specify root for the ansible_user, you must set ansible_become to True and assign the user sudo permissions. </span>

<span class="token assign-left variable">ansible_become</span><span class="token operator">=</span>True 

<span class="token comment"># Specify the path and file name of the kubeconfig file for your cluster. </span>

<span class="token assign-left variable">openshift_kubeconfig_path</span><span class="token operator">=</span><span class="token string">&quot;~/.kube/config&quot;</span> 

<span class="token comment"># List each RHEL machine to add to your cluster. You must provide the fully-qualified domain name for each host. This name is the hostname that the cluster uses to access the machine, so set the correct public or private name to access the machine.  </span>

<span class="token punctuation">[</span>new_workers<span class="token punctuation">]</span> 

worker1.ocp.isv.local 

worker2.ocp.isv.local 

worker3.ocp.isv.local 
</code></pre></div><ol start="2"><li>Navigate to the Ansible playbook directory:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># cd /usr/share/ansible/openshift-ansible </span>
</code></pre></div><ol start="3"><li>Run the following playbook to add RHEL 8 worker nodes to the existing cluster:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># ansible-playbook -i /&lt;path&gt;/inventory/hosts playbooks/scaleup.yml </span>
</code></pre></div><p>For path, specify the path to the Ansible inventory file that you created.</p> <ol start="4"><li>Verify that the worker nodes are added to the cluster using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># oc get nodes </span>
</code></pre></div><p>The following output is displayed:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>NAME			STATUS	ROLES		AGE	VERSION 

master0.ocp.isv.local	Ready	master,worker	13d	v1.23.3+e419edf 

master1.ocp.isv.local	Ready	master,worker	13d	v1.23.3+e419edf 

master2.ocp.isv.local	Ready	master,worker	13d	v1.23.3+e419edf 

worker1.ocp.isv.local	Ready	worker		23h	v1.23.5+3afdacb 

worker2.ocp.isv.local	Ready	worker		23h	v1.23.5+3afdacb 

worker3.ocp.isv.local	Ready	worker		23h	v1.23.5+3afdacb 
</code></pre></div><ol start="5"><li>Once the worker nodes are added to the cluster, set the mastersSchedulable parameter as false to ensure that the master nodes are not used to schedule pods.</li> <li>Edit the schedulers.config.openshift.io resource.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># oc edit schedulers.config.openshift.io cluster </span>
</code></pre></div><ol start="2"><li>Configure the mastersSchedulable parameter.</li></ol> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> config.openshift.io/v1  

<span class="token key atrule">kind</span><span class="token punctuation">:</span> Scheduler  

<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  

<span class="token key atrule">creationTimestamp</span><span class="token punctuation">:</span> “2019<span class="token punctuation">-</span>09<span class="token punctuation">-</span>10T03<span class="token punctuation">:</span>04<span class="token punctuation">:</span>05Z&quot; 

<span class="token key atrule">generation</span><span class="token punctuation">:</span> 1 

<span class="token key atrule">name</span><span class="token punctuation">:</span> cluster 

<span class="token key atrule">resourceVersion</span><span class="token punctuation">:</span> “433&quot; 

<span class="token key atrule">selfLink</span><span class="token punctuation">:</span> /apis/config.openshift.io/v1/schedulers/cluster 

<span class="token key atrule">uid</span><span class="token punctuation">:</span> a636d30a<span class="token punctuation">-</span>d377<span class="token punctuation">-</span>11e9<span class="token punctuation">-</span>88d4<span class="token punctuation">-</span>0a60097bee62 

<span class="token key atrule">spec</span><span class="token punctuation">:</span> 

<span class="token key atrule">mastersSchedulable</span><span class="token punctuation">:</span> false  

<span class="token key atrule">policy</span><span class="token punctuation">:</span> 

<span class="token key atrule">name</span><span class="token punctuation">:</span> “&quot; 

<span class="token key atrule">status</span><span class="token punctuation">:</span> <span class="token punctuation">{</span> <span class="token punctuation">}</span> 
</code></pre></div><p><strong>NOTE</strong></p> <p>Set the mastersSchedulable to true to allow Control Plane nodes to be schedulable or false to disallow Control Plane nodes to be schedulable.</p> <ol start="3"><li>Save the file to apply the changes.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># oc get nodes </span>
</code></pre></div><ul><li>The following output is displayed:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>NAME			STATUS	ROLES	AGE	VERSION 

master0.ocp.isv.local	Ready	master	13d	v1.23.3+e419edf 

master1.ocp.isv.local	Ready	master	13d	v1.23.3+e419edf 

master2.ocp.isv.local	Ready	master	13d	v1.23.3+e419edf 

worker1.ocp.isv.local	Ready	worker	23h	v1.23.5+3afdacb 

worker2.ocp.isv.local	Ready	worker	23h	v1.23.5+3afdacb 

worker3.ocp.isv.local	Ready	worker	23h	v1.23.5+3afdacb 
</code></pre></div><p><strong>NOTE</strong></p> <p>To add more worker nodes, update the worker details in HAProxy and BIND DNS on head nodes and then add RHEL 8.5 worker nodes to the RHOCP cluster. For more information on adding worker nodes, see the <a href="bookmark://_Adding_RHEL_compute">Adding RHEL compute node to OpenShift cluster</a> section.</p> <p>For information on using storage on RHOCP cluster, see <a href="bookmark://_Solution_deployment_using">Solution deployment using storage</a> section.</p> <p>To deploy a sample NGINX application on RHOCP 4.10 using Ephemeral storage, see the <a href="bookmark://_Deploying_sample_application">Deploying sample application on OCP 4.10 using Ephemeral storage</a> section.</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/hpe-solutions-openshift/4.10-dl/Troubleshooting-Using-Manual-Processes/Configuring-Squid-Proxy.html" class="prev">
        Deploying Squid proxy on head nodes
      </a></span> <span class="next"><a href="/hpe-solutions-openshift/4.10-dl/Resosurces-and-additional-links/Resources.html">
        Resources and Additional Links
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/hpe-solutions-openshift/4.10-dl/assets/js/app.d2994e5a.js" defer></script><script src="/hpe-solutions-openshift/4.10-dl/assets/js/2.7c26c33b.js" defer></script><script src="/hpe-solutions-openshift/4.10-dl/assets/js/16.d786a800.js" defer></script>
  </body>
</html>
