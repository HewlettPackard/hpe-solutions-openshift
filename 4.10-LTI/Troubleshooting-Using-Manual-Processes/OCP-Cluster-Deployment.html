<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Generating Kubernetes manifests and ignition files | OpenShift Container Platform 4.10 on HPE DL365 Gen10 Plus Servers</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="Hewlett Packard Enterprise">
    
    <link rel="preload" href="/hpe-solutions-openshift/4.10-LTI/assets/css/0.styles.c1eedc8a.css" as="style"><link rel="preload" href="/hpe-solutions-openshift/4.10-LTI/assets/js/app.362a0d64.js" as="script"><link rel="preload" href="/hpe-solutions-openshift/4.10-LTI/assets/js/2.7c26c33b.js" as="script"><link rel="preload" href="/hpe-solutions-openshift/4.10-LTI/assets/js/16.ffae62f9.js" as="script"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/10.f1cb13d3.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/11.061e6989.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/12.4be51010.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/13.af34e55a.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/14.2d32f75a.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/15.3d123885.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/17.15c44ee1.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/18.01acf1b0.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/19.d5f0f5c9.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/20.38456837.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/21.46035798.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/22.7fe20f6d.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/23.71024d6a.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/24.cabc3f67.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/25.aeaa4730.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/26.1f391f8b.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/3.3fad8a74.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/4.7f10a581.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/5.e7dabacf.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/6.67c17003.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/7.268c772b.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/8.d53d4750.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.10-LTI/assets/js/9.86abf176.js">
    <link rel="stylesheet" href="/hpe-solutions-openshift/4.10-LTI/assets/css/0.styles.c1eedc8a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/hpe-solutions-openshift/4.10-LTI/" class="home-link router-link-active"><!----> <span class="site-name">OpenShift Container Platform 4.10 on HPE DL365 Gen10 Plus Servers</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/hpe-solutions-openshift/4.10-LTI/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="http://www.hpe.com/info/ra" target="_blank" rel="noopener noreferrer" class="nav-link external">
  RA Library
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/hpe-solutions-openshift/4.10-LTI/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="http://www.hpe.com/info/ra" target="_blank" rel="noopener noreferrer" class="nav-link external">
  RA Library
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Red Hat OpenShift Container Platform 4.10 on DL Servers</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Solution Overview</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Solution Components</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Solution Deployment</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Storage</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Additional Features and Functionality</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Troubleshooing by Using Manual Processes</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hpe-solutions-openshift/4.10-LTI/Troubleshooting-Using-Manual-Processes/Preparing-execution-environment.html" class="sidebar-link">Preparing the execution environment for RHOCP worker3 node</a></li><li><a href="/hpe-solutions-openshift/4.10-LTI/Troubleshooting-Using-Manual-Processes/Deploying-OS-on-Head-Nodes.html" class="sidebar-link">Deploying RHOCP cluster manually</a></li><li><a href="/hpe-solutions-openshift/4.10-LTI/Troubleshooting-Using-Manual-Processes/Installing-and-Configuring-Bind-DNS.html" class="sidebar-link">Installing and configuring master/child Bind DNS on head nodes</a></li><li><a href="/hpe-solutions-openshift/4.10-LTI/Troubleshooting-Using-Manual-Processes/Configuring-Squid-Proxy.html" class="sidebar-link">Deploying Squid proxy on head nodes</a></li><li><a href="/hpe-solutions-openshift/4.10-LTI/Troubleshooting-Using-Manual-Processes/OCP-Cluster-Deployment.html" aria-current="page" class="active sidebar-link">Generating Kubernetes manifests and ignition files</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Resosurces and Additional Links</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="generating-kubernetes-manifests-and-ignition-files"><a href="#generating-kubernetes-manifests-and-ignition-files" class="header-anchor">#</a> Generating Kubernetes manifests and ignition files</h1> <p>The manifests and ignition files define the master node and worker node configuration and are key components of the RHOCP 4 installation.</p> <p>Prerequisites:</p> <p>Before creating the manifest files and ignition files, it is necessary to download the RHOCP 4 packages.</p> <ul><li>Download the required packages on the installer VM with the following playbook:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/download_ocp_package.yml
</code></pre></div><p>To generate Kubernetes manifests and ignition files:</p> <ol><li>Generate Kubernetes manifest file with the following playbook.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/generate_manifest.yml
</code></pre></div><ol><li>Find the ignition files in the following path:</li></ol> <p>/opt/ hpe-solutions-openshift/DL-LTI-Openshift/playbooks/roles/generate_ignition_files/ignitions/</p> <ol><li>When the ignition files are generated, export the kubeconfig file with the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token builtin class-name">export</span> <span class="token assign-left variable">KUBECONFIG</span><span class="token operator">=</span> /opt/ hpe-solutions-openshift/DL-LTI-Openshift/playbooks/roles/generate_ignition_files/ignitions/auth/kubeconfig
</code></pre></div><p><strong>Installing and configuring iPXE server</strong></p> <p>To install and configure an iPXE server:</p> <ol><li>Browse to the following directory on the Ansible engine.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token builtin class-name">cd</span> /opt/ hpe-solutions-openshift/DL-LTI-Openshift/
</code></pre></div><ol><li><p>Enter the values as per your setup in input.yaml file.</p></li> <li><p>Execute the following playbook:</p></li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/deploy_ipxe_ocp.yml
</code></pre></div><p><strong>Creating bootstrap and master VM on KVM nodes</strong></p> <p>To create bootstrap and RHOCP master VMs on your RHEL 8 Kernel-based Virtual Machine (KVM) host:</p> <ul><li>Run the following virt-install command:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>$ virt-install <span class="token parameter variable">-n</span> boot <span class="token parameter variable">--description</span> <span class="token string">&quot;boot&quot;</span> <span class="token parameter variable">--ram</span><span class="token operator">=</span><span class="token number">16384</span> <span class="token parameter variable">--vcpu</span><span class="token operator">=</span><span class="token number">10</span> --os-type<span class="token operator">=</span>Linux --os-variant<span class="token operator">=</span>rhel8.0 <span class="token parameter variable">--noreboot</span> <span class="token parameter variable">--disk</span> <span class="token assign-left variable">pool</span><span class="token operator">=</span>home,bus<span class="token operator">=</span>virtio,size<span class="token operator">=</span><span class="token number">100</span> <span class="token parameter variable">--serial</span> pty <span class="token parameter variable">--console</span> pty <span class="token parameter variable">--pxe</span> <span class="token parameter variable">--network</span> <span class="token assign-left variable">bridge</span><span class="token operator">=</span>bridge0,mac<span class="token operator">=</span><span class="token operator">&lt;</span>mac address<span class="token operator">&gt;</span>

Waiting <span class="token keyword">for</span> the bootstrap process to complete

The bootstrap process <span class="token keyword">for</span> RHOCP begins after the cluster nodes first boot into the persistent RHCOS environment that has been installed to disk. The configuration information provided through the ignition config files is used to initialize the bootstrap process and <span class="token function">install</span> RHOCP on the machines. You must <span class="token function">wait</span> <span class="token keyword">for</span> the bootstrap process to complete.
</code></pre></div><ol><li><p>Login to the installer VM as root user.</p></li> <li><p>Execute the following command to bootstrap the nodes:</p></li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ openshift-install wait-for bootstrap-complete --log-level<span class="token operator">=</span>debug
</code></pre></div><p>The following output is displayed:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>DEBUG OpenShift Installer v4.10

DEBUG Built from commit 425e4ff0037487e32571258640b39f56d5ee5572

INFO Waiting up to 30m0s <span class="token keyword">for</span> the Kubernetes API at https://api.ocp.pxelocal.local:6443<span class="token punctuation">..</span>.

INFO API v1.23.3+e419edf up

INFO Waiting up to 30m0s <span class="token keyword">for</span> bootstrapping to complete<span class="token punctuation">..</span>.

DEBUG Bootstrap status: complete

INFO It is now safe to remove the bootstrap resources
</code></pre></div><p><strong>NOTE</strong></p> <p>Shut down or remove the bootstrap node after step 1 and step 2 are complete.</p> <ol><li>Provide the PV storage for the registry. Set the image registry storage to an empty directory with the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc patch configs.imageregistry.operator.openshift.io cluster <span class="token parameter variable">--type</span> merge <span class="token parameter variable">--patch</span> <span class="token string">'{&quot;spec&quot;:{&quot;storage&quot;:{&quot;emptyDir&quot;:{}}}}'</span> 
</code></pre></div><ol><li>Complete the RHOCP 4 cluster installation with the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ openshift-install wait-for install-complete --log-level<span class="token operator">=</span>debug
</code></pre></div><p>The following output is displayed:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>DEBUG OpenShift Installer v4.10

DEBUG Built from commit 6ed04f65b0f6a1e11f10afe658465ba8195ac459 

INFO Waiting up to 30m0s <span class="token keyword">for</span> the cluster at https://api.rrocp.pxelocal.local:6443 to initialize<span class="token punctuation">..</span>. 

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">99</span>% complete 

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">99</span>% complete, waiting on authentication, console,image-registry 

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">99</span>% complete 

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Working towards <span class="token number">4.10</span>: <span class="token number">100</span>% complete, waiting on image-registry 

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Cluster operator image-registry is still updating 

DEBUG Still waiting <span class="token keyword">for</span> the cluster to initialize: Cluster operator image-registry is still updating 

DEBUG Cluster is initialized 

INFO Waiting up to 10m0s <span class="token keyword">for</span> the openshift-console route to be created<span class="token punctuation">..</span>.

DEBUG Route found <span class="token keyword">in</span> openshift-console namespace: console 

DEBUG Route found <span class="token keyword">in</span> openshift-console namespace: downloads 

DEBUG OpenShift console route is created 

INFO Install complete<span class="token operator">!</span> 

INFO Access the OpenShift web-console here: https://console-openshift-console.apps.ocp.isv.local

INFO Login to the console with user: kubeadmin, password: a6hKv-okLUA-Q9p3q-UXLc3

The RHOCP cluster is successfully installed.
</code></pre></div><p><strong>Running Red Hat OpenShift Container Platform Console</strong></p> <p>Prerequisites:</p> <ul><li>The RHOCP cluster installation must be complete</li></ul> <p><strong>NOTE</strong></p> <p>The installer machine provides the Red Hat OpenShift Container Platform Console link and login details when the RHOCP cluster installation is complete.</p> <p>To access the Red Hat OpenShift Container Platform Console:</p> <ol><li>Open a web browser and enter the following link:</li></ol> <p>https://console-openshift-console.apps.ocp.isv.local</p> <ol><li>Log in to the Red Hat OpenShift Container Platform Console with the following credentials:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>- Username <span class="token builtin class-name">:</span> kubeadmin
- Password <span class="token builtin class-name">:</span>  <span class="token operator">&lt;</span>Password<span class="token operator">&gt;</span>
</code></pre></div><p><strong>NOTE</strong></p> <p>If the password is lost or forgotten, search for the kubeadmin-password file located in the /opt/ hpe-solutions-openshift/DL-LTI-Openshift/playbooks/roles/generate_ignition_files/ignitions/auth/kubeadmin-password directory on the installer machine.</p> <p>The following figure shows the Red Hat OpenShift Container Platform Console after successful deployment:</p> <p><img src="/hpe-solutions-openshift/4.10-LTI/assets/img/f25.2db677f2.png" alt=""></p> <p><strong>FIGURE</strong> <strong>25</strong> Red Hat OpenShift Container Platform Console login screen</p> <p><strong>Adding RHEL 8.6 Worker nodes to RHOCP cluster</strong></p> <p><strong>Creating RHEL 7.9 installer machine on head nodes</strong></p> <p>To create a RHEL7.9 VM for adding RHEL 8.6 workers to the RHOCP cluster:</p> <ul><li>Run the following command on your RHEL 8 KVM host using the virt-install utility:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>$ virt-install <span class="token parameter variable">--name</span> Installer <span class="token parameter variable">--memory</span> <span class="token number">2048</span> <span class="token parameter variable">--vcpus</span> <span class="token number">2</span> <span class="token parameter variable">--disk</span> <span class="token assign-left variable">size</span><span class="token operator">=</span><span class="token number">80</span> --os-variant rhel7.0 <span class="token parameter variable">--cdrom</span> /home/username/Downloads/RHEL7.iso
</code></pre></div><p><a href="https://docs.openshift.com/container-platform/4.10/machine_management/adding-rhel-compute.html#rhel-preparing-playbook-machine_adding-rhel-compute" target="_blank" rel="noopener noreferrer"><strong>Setting up RHEL 7.9 installer machine</strong><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>To set up the installer machine running RHEL 7.9 and run the playbook:</p> <ol><li>Log in to the RHEL7.9 Installer Machine and then register and attach the host pool with Red Hat using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager register
</code></pre></div><ol><li>Generate a list of available subscriptions using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager list <span class="token parameter variable">--available</span> <span class="token parameter variable">--matches</span> <span class="token string">'*OpenShift*'</span>
</code></pre></div><ol><li>Find the pool ID for RHOCP subscription from the output generated in step 2 and add it in the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager attach <span class="token parameter variable">--pool</span><span class="token operator">=</span><span class="token operator">&lt;</span>pool_id<span class="token operator">&gt;</span>
</code></pre></div><ol><li>Enable the repositories required by RHOCP 4.10 with the following commands:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager repos <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-rpms&quot;</span> <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-extras-rpms&quot;</span> <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-ansible-2.9-rpms&quot;</span> <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-7-server-ose-4.10-rpms&quot;</span>
</code></pre></div><ol><li>Install the required packages including openshift-ansible.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ yum <span class="token function">install</span> openshift-ansible openshift-clients jq
</code></pre></div><p><strong>Setting up RHEL worker node</strong></p> <p>Prerequisites:</p> <ul><li>The RHEL 8.6 OS must be deployed on the worker nodes</li></ul> <p>To set up a RHEL worker node for each worker node perform the following:</p> <ol><li>Log in to the RHEL host and then register and attach the host pool with Red Hat using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager register
</code></pre></div><ol><li>Generate a list of available subscriptions using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager list <span class="token parameter variable">--available</span> <span class="token parameter variable">--matches</span> <span class="token string">'*OpenShift*'</span>
</code></pre></div><ol><li>Find the pool ID for RHOCP subscription from the output generated in step 2 and add it in the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager attach <span class="token parameter variable">--pool</span><span class="token operator">=</span><span class="token operator">&lt;</span>pool_id<span class="token operator">&gt;</span>
</code></pre></div><ol><li>Enable the repositories required by RHOCP 4.10 with the following commands:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ subscription-manager repos <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-8-for-x86_64-baseos-rpms&quot;</span> <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhel-8-for-x86_64-appstream-rpms&quot;</span> <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;rhocp-4.10-for-rhel-8-x86_64-rpms&quot;</span> <span class="token punctuation">\</span>

<span class="token parameter variable">--enable</span><span class="token operator">=</span><span class="token string">&quot;fast-datapath-for-rhel-8-x86_64-rpms&quot;</span>
</code></pre></div><ol><li>Stop and disable firewalld on the host.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ systemctl disable <span class="token parameter variable">--now</span> firewalld.service
</code></pre></div><p><strong>Adding RHEL worker node to RHOCP cluster using RHEL 7.9 installer machine</strong></p> <p>This section covers the steps to add worker nodes that use Red Hat Enterprise Linux 8 as the operating system to an RHOCP 4.10 cluster.</p> <p>Prerequisites:</p> <ul><li>The required packages must be installed, and the necessary configuration must be performed on the RHEL 7.9 installer machine</li> <li>RHEL hosts must be prepared for installation</li></ul> <p>To add RHEL 8 worker nodes manually to an existing cluster using RHEL 7.9 installer VM machine:</p> <ol><li>Create an Ansible inventory file in the /<path></path>inventory/hosts directory. This inventory file defines your worker nodes  and the required</li></ol> <p>variables:</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token punctuation">[</span>all:vars<span class="token punctuation">]</span>

<span class="token comment"># Specify the username that runs the Ansible tasks on the remote compute machines.</span>

<span class="token comment"># ansible_user=root</span>

<span class="token comment"># If you do not specify root for the ansible_user, you must set ansible_become to True and assign the user sudo permissions.</span>

<span class="token assign-left variable">ansible_become</span><span class="token operator">=</span>True

<span class="token comment"># Specify the path and file name of the kubeconfig file for your cluster.</span>

<span class="token assign-left variable">openshift_kubeconfig_path</span><span class="token operator">=</span><span class="token string">&quot;~/.kube/config&quot;</span>

<span class="token comment"># List each RHEL machine to add to your cluster. You must provide the fully-qualified domain name for each host. This name is the hostname that the cluster uses to access the machine, so set the correct public or private name to access the machine.</span>

<span class="token punctuation">[</span>new_workers<span class="token punctuation">]</span>

worker1.ocp.isv.local

worker2.ocp.isv.local

worker3.ocp.isv.local
</code></pre></div><ol><li>Navigate to the Ansible playbook directory:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token builtin class-name">cd</span> /usr/share/ansible/openshift-ansible
</code></pre></div><ol><li>Run the following playbook to add RHEL 8 worker nodes to the existing cluster:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> /<span class="token operator">&lt;</span>path/<span class="token operator">&gt;</span>/inventory/hosts playbooks/scaleup.yml
</code></pre></div><p>For /<path></path>, specify the path to the Ansible inventory file that you created.</p> <ol><li>Verify that the worker nodes are added to the cluster using the following command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc get nodes
</code></pre></div><p>The following output is displayed:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>NAMESTATUSROLESAGEVERSION

master0.ocp.isv.localReadymaster,worker13dv1.23.3+e419edf

master1.ocp.isv.localReadymaster,worker13dv1.23.3+e419edf

master2.ocp.isv.localReadymaster,worker13dv1.23.3+e419edf

worker1.ocp.isv.localReadyworker23hv1.23.5+3afdacb

worker2.ocp.isv.localReadyworker23hv1.23.5+3afdacb

worker3.ocp.isv.localReadyworker23hv1.23.5+3afdacb
</code></pre></div><ol><li><p>Once the worker nodes are added to the cluster, set the mastersSchedulable parameter as false to ensure that the master nodes are not used to schedule pods.</p></li> <li><p>Edit the schedulers.config.openshift.io resource.</p></li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc edit schedulers.config.openshift.io cluster
</code></pre></div><ol><li>Configure the mastersSchedulable parameter.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>apiVersion: config.openshift.io/v1

kind: Scheduler

metadata:

creationTimestamp: <span class="token string">&quot;2019-09-10T03:04:05Z&quot;</span>

generation: <span class="token number">1</span>

name: cluster

resourceVersion: <span class="token string">&quot;433&quot;</span>

selfLink: /apis/config.openshift.io/v1/schedulers/cluster

uid: a636d30a-d377-11e9-88d4-0a60097bee62

spec:

mastersSchedulable: <span class="token boolean">false</span>

policy:

name: <span class="token string">&quot;&quot;</span>

status: <span class="token punctuation">{</span> <span class="token punctuation">}</span>
</code></pre></div><p><strong>NOTE</strong></p> <p>Set the mastersSchedulable to true to allow Control Plane nodes to be schedulable or false to disallow Control Plane nodes to be schedulable.</p> <ol><li>Save the file to apply the changes.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc get nodes
</code></pre></div><ul><li>The following output is displayed:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>NAMESTATUSROLESAGEVERSION

master0.ocp.isv.localReadymaster13dv1.23.3+e419edf

master1.ocp.isv.localReadymaster13dv1.23.3+e419edf

master2.ocp.isv.localReadymaster13dv1.23.3+e419edf

worker1.ocp.isv.localReadyworker23hv1.23.5+3afdacb

worker2.ocp.isv.localReadyworker23hv1.23.5+3afdacb

worker3.ocp.isv.localReadyworker23hv1.23.5+3afdacb
</code></pre></div><p><strong>NOTE</strong></p> <p>To add more worker nodes, update the worker details in HAProxy and BIND DNS on head nodes and then add RHEL 8.6 worker nodes to the RHOCP cluster. For more information on adding worker nodes, see the <a href="bookmark://_Adding_RHEL_compute">Adding RHEL compute node to OpenShift cluster</a> section.</p> <p>For information on using storage on RHOCP cluster, see <a href="bookmark://_Solution_deployment_using">Solution deployment using storage</a> section.</p> <p>To deploy a sample NGINX application on RHOCP 4.10 using Ephemeral storage, see the <a href="bookmark://_Deploying_sample_application">Deploying sample application on OCP 4.10 using Ephemeral storage</a> section.</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/hpe-solutions-openshift/4.10-LTI/Troubleshooting-Using-Manual-Processes/Configuring-Squid-Proxy.html" class="prev">
        Deploying Squid proxy on head nodes
      </a></span> <span class="next"><a href="/hpe-solutions-openshift/4.10-LTI/Resosurces-and-additional-links/Resources.html">
        Resources and Additional Links
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/hpe-solutions-openshift/4.10-LTI/assets/js/app.362a0d64.js" defer></script><script src="/hpe-solutions-openshift/4.10-LTI/assets/js/2.7c26c33b.js" defer></script><script src="/hpe-solutions-openshift/4.10-LTI/assets/js/16.ffae62f9.js" defer></script>
  </body>
</html>
