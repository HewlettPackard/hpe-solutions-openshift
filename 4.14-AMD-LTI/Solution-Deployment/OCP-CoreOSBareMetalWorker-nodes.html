<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Adding BareMetal CoreOS worker nodes to RHOCP cluster using Ansible playbooks | OpenShift Container Platform 4.14 on HPE DL AMD Gen11 Servers</title>
    <meta name="description" content="Hewlett Packard Enterprise">
    
    
    <link rel="preload" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/css/0.styles.350242d5.css" as="style"><link rel="preload" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/app.4d58c519.js" as="script"><link rel="preload" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/15.7ac29fb4.js" as="script"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/10.d904139f.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/11.50f5b458.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/12.812c3f05.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/13.b106d720.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/14.ebe9997c.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/16.bda92651.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/17.d97c7055.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/18.59107dd9.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/19.ce351482.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/2.7dc22b72.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/3.e6e4ed9b.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/4.aed6a745.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/5.71459368.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/6.ae8cc0e2.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/7.481e1954.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/8.eb3fc9fb.js"><link rel="prefetch" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/9.835e078e.js">
    <link rel="stylesheet" href="/hpe-solutions-openshift/4.14-AMD-LTI/assets/css/0.styles.350242d5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/hpe-solutions-openshift/4.14-AMD-LTI/" class="home-link router-link-active"><!----> <span class="site-name">OpenShift Container Platform 4.14 on HPE DL AMD Gen11 Servers</span></a> <div class="links" style="max-width:nullpx;"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/hpe-solutions-openshift/4.14-AMD-LTI/" class="nav-link">Home</a></div><div class="nav-item"><a href="http://www.hpe.com/info/ra" target="_blank" rel="noopener noreferrer" class="nav-link external">
  RA Library
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/hpe-solutions-openshift/4.14-AMD-LTI/" class="nav-link">Home</a></div><div class="nav-item"><a href="http://www.hpe.com/info/ra" target="_blank" rel="noopener noreferrer" class="nav-link external">
  RA Library
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><div class="sidebar-group first collapsable"><p class="sidebar-heading"><span>Red Hat OpenShift Container Platform 4.14 on HPE DL325 &amp; DL385 Gen11 Servers</span> <span class="arrow right"></span></p> <!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>Solution Overview</span> <span class="arrow right"></span></p> <!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>Solution Components</span> <span class="arrow right"></span></p> <!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading open"><span>Solution Deployment</span> <span class="arrow down"></span></p> <ul class="sidebar-group-items"><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/Solution-deployment-flow.html" class="sidebar-link">SOLUTION DEPLOYMENT WORKFLOW</a></li><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/Preparing-execution-environment.html" class="sidebar-link">Preparing the execution environment for RHOCP worker3 node</a></li><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/OCP-Cluster-deployment.html" class="sidebar-link">Deploying RHOCP cluster using Ansible playbooks</a></li><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/OCP-worker-nodes.html" class="sidebar-link">Adding BareMetal RHEL 8.8 worker nodes to RHOCP cluster using Ansible playbooks</a></li><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/OCP-CoreOSWorker-nodes.html" class="sidebar-link">Adding RH CoreOS worker nodes to RHOCP cluster using Ansible playbooks</a></li><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/OCP-CoreOSBareMetalWorker-nodes.html" aria-current="page" class="active sidebar-link">Adding BareMetal CoreOS worker nodes to RHOCP cluster using Ansible playbooks</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/Deploying-sample-application-using-Ephemeral-storage.html" class="sidebar-link">Deploying sample application on RHOCP 4.14 using Ephemeral storage</a></li></ul></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>Additional Features and Functionality</span> <span class="arrow right"></span></p> <!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>Resources and Additional Links</span> <span class="arrow right"></span></p> <!----></div></li></ul> </div> <div class="page"> <div class="content"><h1 id="adding-baremetal-coreos-worker-nodes-to-rhocp-cluster-using-ansible-playbooks"><a href="#adding-baremetal-coreos-worker-nodes-to-rhocp-cluster-using-ansible-playbooks" class="header-anchor">#</a> <strong>Adding BareMetal CoreOS worker nodes to RHOCP cluster using Ansible playbooks</strong></h1> <p>The Lite Touch Installation (LTI) package includes Ansible playbooks with scripts to add the bare metal CoreOS worker nodes to the RHOCP cluster. You can use one of the following two methods to add the CoreOS worker nodes:</p> <ul><li><strong>Run a consolidated playbook:</strong> This method includes a single playbook, site.yml, that contains a script to perform all the tasks for adding the CoreOS worker nodes to the existing RHOCP cluster. To run LTI using a consolidated playbook:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts site.yml --ask-vault-pass
</code></pre></div><div class="tip custom-block"><p class="custom-block-title">NOTE</p> <p>The default password for the Ansible vault file is <strong>changeme</strong></p></div> <p>If network interface bonding is required on the bare metal worker nodes, follow the Step 4 and then proceed for the CSR certificate verfication.</p> <ul><li><strong>Run individual playbooks:</strong> This method includes multiple playbooks with scripts that enable you to deploy specific tasks for adding the CoreOS worker nodes to the existing RHOCP cluster. The playbooks in this method must be executed in a specific sequence to add the worker nodes.</li></ul> <p>The following table includes the purpose of each playbook required for the deployment:</p> <p><strong>TABLE 9.</strong> Playbook Description</p> <table><thead><tr><th style="text-align:left">Playbook</th> <th style="text-align:left">Description</th></tr></thead> <tbody><tr><td style="text-align:left">binddns.yml</td> <td style="text-align:left">This playbook contains the script to deploy bind dns on three worker nodes and it will work as both Active &amp; Passive.</td></tr> <tr><td style="text-align:left">haproxy.yml</td> <td style="text-align:left">This playbook contains the script to deploy haproxy on the worker nodes and it will act as Active.</td></tr> <tr><td style="text-align:left">deploy_ipxe_ocp.yml</td> <td style="text-align:left">This playbook contains the script to deploy the ipxe code on the worker machine.</td></tr></tbody></table> <p>To run individual playbooks do one of the following:</p> <ol><li>Edit site.yml file and add a comment for all the playbooks except the ones that you want to execute.</li></ol> <p>For example, add the following comments in the site.yml file to bind dns on the worker nodes:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>import_playbook: playbooks/binddns.yml
<span class="token comment"># import_playbook: playbooks/haproxy.yml</span>
<span class="token comment"># import_playbook: playbooks/deploy_ipxe_ocp.yml</span>
</code></pre></div><p>OR</p> <p>Run the individual YAML files using the following command:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/<span class="token operator">&lt;</span>yaml_filename<span class="token operator">&gt;</span>.yml --ask-vault-pass
</code></pre></div><p>For example, run the following YAML file to bind dns to the worker nodes:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/binddns.yml --ask-vault-pass
</code></pre></div><p>For more information on executing individual playbooks, see the consecutive sections.</p> <h3 id="adding-coreos-worker-nodes"><a href="#adding-coreos-worker-nodes" class="header-anchor">#</a> <strong>Adding CoreOS worker nodes</strong></h3> <p>This section covers the steps to add RHCOS worker nodes to an existing Red Hat OpenShift Container Platform cluster.</p> <ol><li>Login to the Installer VM.</li></ol> <p>This installer VM was created as a KVM VM on one of the head nodes using the rhel8_installerVM.yml playbook. For more information, see the <a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/OCP-Cluster-deployment.html#creating-rhel-8-installer-machine">Creating RHEL 8 installer machine</a> section.</p> <ol start="2"><li>Navigate to the $BASE_DIR(<strong>/opt/hpe-solutions-openshift/DL-LTI-Openshift/</strong>) directory, then copy <strong>input file and hosts</strong> file to $BASE_DIR/coreos_BareMetalworker_nodes/ and later update ocp worker details in input file.</li></ol> <div class="language- extra-class"><pre class="language-text"><code>ansible-vault edit input.yaml
------------------------------------------------------------------------------------------------------------
ocp_workers:
 - name: worker1
   ip: 172.28.xx.xxx
   fqdn: xxx.ocp.isv.local                   #ex. mworker1.ocp.isv.local
   mac_address: XX:XX:XX:XX:XX:XX			 #For BareMetal core os worker update mac address of server NIC
 - name: worker2
   ip: 172.28.xx.xxx
   fqdn: xxx.ocp.isv.local                 #ex. mworker2.ocp.isv.local
   mac_address: XX:XX:XX:XX:XX:XX 		   #For BareMetal core os worker update mac address of server NIC
 - name: worker3
   ip: 172.28.xx.xxx
   fqdn: xxx.ocp.isv.local                   #ex. mworker3.ocp.isv.local
   mac_address: XX:XX:XX:XX:XX:XX 		     #For BareMetal core os worker update mac address of server NIC
------------------------------------------------------------------------------------------------------------
</code></pre></div><div class="tip custom-block"><p class="custom-block-title">NOTE</p> <p>import the hosts file from the $BASE_DIR</p> <p>ansible vault password is <strong>changeme</strong></p></div> <ol start="3"><li>Navigate to the /opt/hpe-solutions-openshift/DL-LTI-Openshift/coreos_BareMetalworker_nodes/ directory add the worker nodes to the cluster using one of the following methods:</li></ol> <ul><li>Run the following sequence of playbooks:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/binddns.yml --ask-vault-pass
$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/haproxy.yml --ask-vault-pass
$ ansible-playbook <span class="token parameter variable">-i</span> hosts playbooks/deploy_ipxe_ocp.yml --ask-vault-pass
</code></pre></div><p>OR</p> <ul><li>If you want to deploy the entire solution to add the RH CoreOS worker nodes to the cluster, execute the following playbook:</li></ul> <div class="language-bash extra-class"><pre class="language-bash"><code>$ ansible-playbook <span class="token parameter variable">-i</span> hosts site.yml --ask-vault-pass
</code></pre></div><ol start="4"><li>Execute the following command for creating bonding on the network interfaces for baremetal CoreOS worker nodes</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">ssh</span> core@<span class="token operator">&lt;</span>CoreOS workerIP<span class="token operator">&gt;</span>
$ <span class="token function">ip</span> <span class="token parameter variable">-o</span> <span class="token function">link</span> show <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'state UP'</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token parameter variable">-F</span> <span class="token string">': '</span> <span class="token string">'{print $2}'</span>                        <span class="token comment">###to retrive only the names of the network interfaces that are currently UP</span>

sample output from above command:
  ens1f0np0
  ens1f1np1

$ <span class="token function">sudo</span> nmcli connection <span class="token function">add</span> <span class="token builtin class-name">type</span> bond con-name <span class="token string">&quot;bond0&quot;</span> ifname bond0
$ <span class="token function">sudo</span> nmcli connection modify bond0 bond.options <span class="token string">&quot;mode=active-backup,downdelay=0,miimon=100,updelay=0&quot;</span>
$ <span class="token function">sudo</span> nmcli connection <span class="token function">add</span> <span class="token builtin class-name">type</span> ethernet slave-type bond con-name bond0-if1 ifname ens1f0np0 master bond0                <span class="token comment">###ens1f0np0 interface names from the sample output</span>
$ <span class="token function">sudo</span> nmcli connection <span class="token function">add</span> <span class="token builtin class-name">type</span> ethernet slave-type bond con-name bond0-if2 ifname ens1f1np1 master bond0             <span class="token comment">###ens1f1np1 interface names from the sample output</span>
$ <span class="token function">sudo</span> nmcli connection up bond0
$ <span class="token function">sudo</span> nmcli connection modify <span class="token string">&quot;bond0&quot;</span> ipv4.addresses <span class="token string">'&lt;&lt;CoreOS IP  with netmask&gt;&gt;'</span> ipv4.gateway <span class="token string">'&lt;&lt;gateway IP&gt;&gt;'</span> ipv4.dns  <span class="token string">'&lt;&lt;dns server IP(all the head node IP)&gt;&gt;'</span> ipv4.dns-search <span class="token string">'&lt;&lt;domain name&gt;&gt;'</span> ipv4.method manual

example:
<span class="token function">sudo</span> nmcli connection modify <span class="token string">&quot;bond0&quot;</span> ipv4.addresses <span class="token string">'172.28.*.*/24'</span> ipv4.gateway <span class="token string">'172.28.*.*'</span> ipv4.dns  <span class="token string">'172.28.*.*,172.28.*.*,172.28.*.*'</span> ipv4.dns-search <span class="token string">'isv.local'</span> ipv4.method manual

$ <span class="token function">sudo</span> <span class="token function">reboot</span>
</code></pre></div><ol start="5"><li>After successful execution of all playbooks, check the node status as below.</li></ol> <p><strong>Approving server certificates (CSR) for newly added nodes</strong></p> <p>The administrator needs to approve the CSR requests generated by each kubelet.</p> <p>You can approve all Pending CSR requests using below command</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc get csr <span class="token parameter variable">-o</span> json <span class="token operator">|</span> jq <span class="token parameter variable">-r</span> <span class="token string">'.items[] | select(.status == {} ) | .metadata.name'</span> <span class="token operator">|</span> <span class="token function">xargs</span> oc adm certificate approve
</code></pre></div><ol start="6"><li>Later, Verify Node status using below command:</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc get nodes
</code></pre></div><ol start="7"><li>Execute the following command to set the parameter mastersSchedulable parameter as false, so that master nodes will not be used to schedule pods.</li></ol> <div class="language-bash extra-class"><pre class="language-bash"><code>$ oc edit scheduler
</code></pre></div></div> <div class="page-edit"><!----> <!----></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/OCP-CoreOSWorker-nodes.html" class="prev">
          Adding RH CoreOS worker nodes to RHOCP cluster using Ansible playbooks
        </a></span> <span class="next"><a href="/hpe-solutions-openshift/4.14-AMD-LTI/Solution-Deployment/Deploying-sample-application-using-Ephemeral-storage.html">
          Deploying sample application on RHOCP 4.14 using Ephemeral storage
        </a>
        →
      </span></p></div> </div> <!----></div></div>
    <script src="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/app.4d58c519.js" defer></script><script src="/hpe-solutions-openshift/4.14-AMD-LTI/assets/js/15.7ac29fb4.js" defer></script>
  </body>
</html>
