###
## Copyright (2018) Hewlett Packard Enterprise Development LP
##
## Licensed under the Apache License, Version 2.0 (the "License");
## You may not use this file except in compliance with the License.
## You may obtain a copy of the License at
##
##Â http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
## See the License for the specific language governing permissions and
## limitations under the License.
####

#RedHat Virtualization Host details 
[rhv]
hmrhvh01.tennet.local  bondip2=20.0.140.8 iscsiaip=30.0.140.8 iscsibip=40.0.140.8 name=hmrhvh01 iqnstring=hmrhvh01 fqdn=hmrhvh01.tennet.local
hmrhvh02.tennet.local  bondip2=20.0.140.9 iscsiaip=30.0.140.9 iscsibip=40.0.140.9 name=hmrhvh02 iqnstring=hmrhvh02 fqdn=hmrhvh02.tennet.local
hmrhvh03.tennet.local  bondip2=20.0.140.10 iscsiaip=30.0.140.10 iscsibip=40.0.140.10 name=hmrhvh03 iqnstring=hmrhvh03 fqdn=hmrhvh03.tennet.local

#RedHat Virtualization Manager/Ovirt Engine FQDN
[rhvm]
ovirtnim.tennet.local

#RHEL 7.6 Physical worker node details
[nworkerhosts]
nimworker01.tennet.local iscsiaip=30.0.9.101 iscsibip=40.0.9.101 iqnstring=nimworker01
nworker02.tennet.local iscsiaip=30.0.9.2 iscsibip=40.0.9.2  iqnstring=nworker02 
nworker03.tennet.local iscsiaip=30.0.9.3 iscsibip=40.0.9.3  iqnstring=nworker03 
nworker04.tennet.local iscsiaip=30.0.9.4 iscsibip=40.0.9.4  iqnstring=nworker04
nimworker05.tennet.local iscsiaip=30.0.9.5 iscsibip=40.0.9.5  iqnstring=nimworker05
nworker06.tennet.local iscsiaip=30.0.9.1 iscsibip=40.0.9.1  iqnstring=nworker06 

#RedHat Virtualization Host for PXE network boot and network bond configuration
[nrhvh]
192.168.4.188 fqdn=hmrhvh01.tennet.local bondip1=10.0.140.8 fqdn=hmrhvh01.tennet.local name=hmrhvh01
192.168.4.189 fqdn=hmrhvh02.tennet.local bondip1=10.0.140.9 fqdn=hmrhvh02.tennet.local name=hmrhvh02
192.168.4.190 fqdn=hmrhvh03.tennet.local bondip1=10.0.140.10 fqdn=hmrhvh03.tennet.local name=hmrhvh03

# FQDN of the Virtual RHEL 7.6 Machines used for the OCP Management nodes
[virtual-nodes]
hm-master01.tennet.local   
hm-master02.tennet.local   
hm-master03.tennet.local   
hm-etcd01.tennet.local    
hm-etcd02.tennet.local   
hm-etcd03.tennet.local   
hm-infra01.tennet.local   
hm-infra02.tennet.local  
hm-infra03.tennet.local 
hm-lb01.tennet.local   
hm-lb02.tennet.local  
#hm-worker01.tennet.local              # uncomment if using physical worker nodes
#hm-worker02.tennet.local              # uncomment if using physical worker nodes
#hm-worker03.tennet.local              # uncomment if using physical worker nodes
#hm-worker04.tennet.local              # uncomment if using physical worker nodes
#hm-worker05.tennet.local              # uncomment if using physical worker nodes
#hm-worker06.tennet.local              # uncomment if using physical worker nodes

#FQDN of the Physical RHEL 7.6 used for the OCP Worker Nodes , comment if using virtual worker nodes
[physical-nodes]
nworker01.tennet.local
nworker02.tennet.local
nworker03.tennet.local
nworker04.tennet.local
nimworker05.tennet.local
nimworker06.tennet.local

[OSEv3:children]
masters
nodes
etcd
lb
infra

#Variables used for OCP 3.11 installation
[OSEv3:vars]
#user used for OCP installation
ansible_ssh_user=oshiftuser
ansible_become=true                                   
openshift_release="3.11"
oreg_auth_user="{{ vault_rhsub_user }}"               
oreg_auth_password="{{ vault_rhsub_pass }}"
oreg_url=registry.redhat.io/openshift3/ose-${component}:${version}
oreg_test_login=false
openshift_deployment_type=openshift-enterprise

# Authenticating with the Active Directory, prerequisite to use the below option is a user created in the Active Directory. comment the below line in case htpasswd is use in cas
openshift_master_identity_providers=[{'name': 'my_ldap_provider', 'challenge': 'true', 'login': 'true', 'kind': 'LDAPPasswordIdentityProvider', 'attributes': {'id': ['dn'], 'email': ['mail'], 'name': ['cn'], 'preferredUsername': ['uid']}, 'bindDN': '', 'bindPassword': '', 'insecure': 'false', 'url': 'ldap://ldap.example.com:389/ou=users,dc=example,dc=com?uid'}] 

#location of the hashed htpasswd file : uncomment the below lines if using an htpasswd for authentication
#openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login':'true', 'challenge': 'true','kind': 'HTPasswdPasswordIdentityProvider',}]
#openshift_master_htpasswd_file=/etc/oshift-hash-pass.htpasswd  

public_hosted_zone=tennet.local

# Load balancer details
load_balancer_hostname=hm-lb01.tennet.local
openshift_master_cluster_hostname=hm-lb01.tennet.local
openshift_master_cluster_public_hostname=hm-lb01.tennet.local
openshift_public_hostname=hm-lb01.tennet.local
# This variable defines the HA method when deploying multiple masters. Supports the native method.
openshift_master_cluster_method=native   
# Set to true to enable the OpenShift SDN plug-in. 
openshift_use_openshift_sdn=true         

#Internal Pod network
# This variable overrides the SDN cluster network CIDR block. This is the network from which pod IPs are assigned. Specify a private block that does not conflict with existing network blocks in your infrastructure to which pods, nodes, or the master might require access. Defaults to 10.128.0.0/14 and cannot be arbitrarily re-configured after deployment
osm_cluster_network_cidr=12.0.0.0/8 

# This variable specifies the size of the per host subnet allocated for pod IPs by OpenShift Container Platform SDN. Defaults to 9 which means that a subnet of size /23 is allocated to each host; for example, given the default 10.128.0.0/14 cluster network, this will allocate 10.128.0.0/23, 10.128.2.0/23, 10.128.4.0/23, and so on. This cannot be re-configured after deployment.

osm_host_subnet_length=9
# Default node selector for automatically deploying registry pods
openshift_registry_selector='node-role.kubernetes.io/infra=true'
# Default node selector for automatically deploying router pods
openshift_router_selector='node-role.kubernetes.io/infra=true'

openshift_enable_service_catalog=true

# To Enable Logging for OCP 3.11 , uncomment the following section
#openshift_logging_install_logging=true
#openshift_logging_es_pvc_dynamic=true
#PVC size for Elasticsearch, change the size depending on the environment
#openshift_logging_es_pvc_size=200Gi                     
#openshift_logging_elasticsearch_storage_type=pvc      
#openshift_logging_es_pvc_prefix=oc-efk-log
#openshift_logging_es_cluster_size=3
#openshift_logging_es_nodeselector={"node-role.kubernetes.io/infra": "true"}
#openshift_logging_kibana_nodeselector={"node-role.kubernetes.io/infra": "true"}
#openshift_logging_curator_nodeselector={"node-role.kubernetes.io/infra": "true"}
#openshift_logging_fluentd_nodeselector={"node-role.kubernetes.io/infra": "true"}
#openshift_logging_es_number_of_replicas=3
#openshift_logging_es_allow_external=true
#openshift_logging_es_hostname=es.router.tennet.local
#Kibana hostname/URL for EFK Logging dashboard
#openshift_logging_kibana_hostname=kibana.router.tennet.local   


#To Enable Monitoring for OCP 3.11, uncomment the following section
#openshift_cluster_monitoring_operator_install=true
#openshift_cluster_monitoring_operator_node_selector={"node-role.kubernetes.io/infra": "true"}
#openshift_cluster_monitoring_operator_prometheus_storage_enabled=true
#openshift_cluster_monitoring_operator_alertmanager_storage_enabled=true
#PVC size for Prometheus, change the size depending on the environment
#openshift_cluster_monitoring_operator_prometheus_storage_capacity=100Gi  
#PVC size for Alertmanager, change the size depending on the environment
#openshift_cluster_monitoring_operator_alertmanager_storage_capacity=20Gi 
#openshift_cluster_monitoring_operator_prometheus_storage_enabled=true
#openshift_cluster_monitoring_operator_alertmanager_storage_enabled=true


[masters]
hm-master01.tennet.local 
hm-master02.tennet.local 
hm-master03.tennet.local 

[etcd]
hm-etcd01.tennet.local
hm-etcd02.tennet.local
hm-etcd03.tennet.local

[lb]
hm-lb01.tennet.local 
hm-lb02.tennet.local

[infra]
hm-infra01.tennet.local 
hm-infra02.tennet.local 
hm-infra03.tennet.local

[nodes]
hm-master01.tennet.local openshift_node_group_name='node-config-master' 
hm-master02.tennet.local openshift_node_group_name='node-config-master' 
hm-master03.tennet.local openshift_node_group_name='node-config-master' 
hm-infra01.tennet.local openshift_node_group_name='node-config-infra'
hm-infra02.tennet.local openshift_node_group_name='node-config-infra'
hm-infra03.tennet.local openshift_node_group_name='node-config-infra'
hm-worker01.tennet.local openshift_node_group_name='node-config-compute'
hm-worker02.tennet.local openshift_node_group_name='node-config-compute'
hm-worker03.tennet.local openshift_node_group_name='node-config-compute'
nimworker04.tennet.local openshift_node_group_name='node-config-compute'
nimworker05.tennet.local openshift_node_group_name='node-config-compute'
nimworker06.tennet.local openshift_node_group_name='node-config-compute'
